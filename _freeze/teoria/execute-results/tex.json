{
  "hash": "c84c4131d743ce69bfb67b48e19b33a3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Misure meccaniche in regime dinamico\"\nauthor: \"Mariolino De Cecco e Paolo Bosetti\"\ndate: \"2025-02-25\"\nformat: \n  html:\n    toc: TRUE\n    html-math-method: katex\n  pdf:\n    toc: TRUE\nengine: knitr\neditor: \n  markdown: \n    wrap: sentence\n---\n\n\n\n\n\n\n\nNella scienza delle misure stanno esplodendo due settori apparentemente non collegati: sensori al silicio, derivanti dalle tecnologie consolidate dei micro-chip, stanno soppiantando i tradizionali sensori (nonostante questi ultimi possiedano qualità metrologiche nettamente superiori); nuovi strumenti di elaborazione dati (PC, DSP, processori, micro-controllori, etc), sempre più potenti ed economici, stanno promuovendo l'impiego di algoritmi sempre più complessi (reti neurali, fuzzy sets, wavelets, etc).\nSi pensi ai moderni smartphone che contengono diversi sensori (una IMU, Inertial Measurement Unit che contiene accelerometri e giroscopi per la misura del moto, videocamere ed in alcuni casi anche telecamere a tempo di volo per la misura in 3 dimensioni) ed un processore estremamente potente a bordo.\n\nI due aspetti, oltre che essere legati allo stesso fenomeno tecnologico, sono concorrenti nello stimolare il seguente approccio: utilizzare sensori di bassa qualità accoppiati a sistemi di acquisizione ed elaborazione complessa dei dati.\nIn altre parole, le necessità di mercato stanno spingendo verso la ricerca di sensori che sfruttino le tecnologie consolidate della lavorazione del silicio che forniscono il duplice vantaggio della produzione in larga scala e quindi basso costo e quello della estrema miniaturizzazione ed integrazione con l'elettronica di condizionamento ed elaborazione segnali che consentono di impiegare algoritmi avanzati capaci di ottenere un'accuratezza adeguata anche da misure effettuate tramite sensori di bassa qualità.\nSi potrebbe citare la tecnologia dei sistemi embedded che, in maniera pervasiva, occupa gli spazi di vita quotidiana (con reti di sistemi di sorveglianza, sensori distribuiti per la domotica, etc) o industriale (reti di sensori per l'ottimizzazione della produzione e la diagnostica del processo produttivo giusto per citare alcuni esempi).\n\nSi potrebbe aggiungere l'enorme sviluppo dell'intelligenza artificiale che si basa sulla raccolta dati, ovvero segnali generalmente variabili nel tempo.\nNon da ultimo è da considerare che per le applicazioni in ambito ingegneria meccatronica si ha a che fare con sistemi autonomi di cui si vuole controllare un certo numero di stati.\nA tale scopo è fondamentale la misura di tali stati che, se incogniti, ovviamente non sarebbero controllabili.\nEbbene in ambito automatico gli stati sono associati a parametri di misura tempovarianti da cui occorre estrapolare delle informazioni tramite elaborazione di segnali tempovarianti.\n\nIn altre parole, l'elaborazione dei segnali acquisiti tramite reti di sensori distribuiti o da un sistema robotico, richiedono ad un ingegnere meccatronico la capacità di elaborarli.\nQuesto per diversi scopi quali sintetizzare una variabile da controllare, ottenere informazioni legate alla diagnostica delle macchine o semplicemente per ridurre il rumore sovrapposto al segnale.\n\nL'obiettivo di questa dispensa è quello di fornire i rudimenti essenziali per il \"signal processing\" che comprendono l'elaborazione nel dominio della frequenza tramite Trasformata di Fourier, il concetto e la stima tramite Taratura Dinamica della Funzione di Trasferimento, la Modellazione a Parametri Concentrati dei sistemi meccanici e conseguente estrapolazione delle Impedenze Generalizzate che consentono di costruire reti analoghe a quelle elettriche per la stima delle relazioni dinamiche che intervengono nei diversi punti del meccanismo.\n\n# Trasformata di Fourier\n\nLa trasformata di Fourier trasforma il segnale dal dominio del tempo al dominio della frequenza.\nIn altre parole una funzione del tempo viene rappresentata, tramite opportuni coefficienti, in una funzione della frequenza evidenziando quali componenti armoniche compaiono nel segnale.\nVi sono proprietà della trasformata di Fourier che ricorrono in altre trasformate quali la WT e la STFT (denominata anche trasformata di Gabor) e che sono essenziali per l'interpretazione dei risultati della trasformazione e di eventuali operazioni in frequenza quali filtraggi.\nTali concetti sono la scomposizione di una funzione secondo una base di funzioni ortonormali e la reversibilità della trasformata.\n\n## Segnali tempovarianti, segnali discreti, vettori\n\nUn segnale funzione del tempo s(t) rappresenta un segnale reale che varia in funzione del tempo senza soluzione di continuità.\nUn segnale discreto è un segnale campionato e quantizzato.\nDunque rappresentabile tramite un vettore $s = \\{s(1), s(2), \\dots, S(N)\\}$, dove $n = 1\\dots N$ sono gli $N$ campioni acquisiti ad una certa frequenza di campionamento $f_c$.\n\nCome vedremo quindi vi sarà una differenza tra la Trasformata di Fourier di un segnale tempovariante da quella di un segnale discreto.\nLa prima ha un carattere ed una utilità simbolica, potremmo dire di concetto.\nLa seconda pratica poiché tutti i segnali che si elaborano mediante processori sono discreti.\n\nNei prossimi sotto-paragrafi passeremo:\n\n-   dalla scomposizione di un vettore su di una base di versori ortonormali\n-   alla scomposizione di un segnale tempovariante periodico su una base di segnali ortonormali\n-   alla scomposizione di un segnale tempovariante non periodico su una base di segnali ortonormali\n-   alla scomposizione di un segnale discreto (ovvero un vettore) su una base di segnali discreti ortonormali (altri vettori).\n\nTutto ciò per comprendere cosa rappresentano le componenti del segnale nel dominio della frequenza (sia esso continuo o discreto) e, tramite il concetto di Funzione di Trasferimento, implementare le elaborazioni che si possono condurre in tale dominio.\nTutto ciò consentirà di capire come gli strumenti di misura di grandezze tempovarianti si comportano con il misurando in base alle caratteristiche dinamiche riassunte proprio dalla loro funzione di trasferimento.\n\n## Scomposizione di un vettore su di una base di versori orto-normali\n\nPer comprendere il concetto di scomposizione di un segnale tempovariante si può pensare al parallelo vettoriale: un vettore nel piano può essere scomposto secondo due direzioni mutuamente ortogonali.\nIn tale maniera si ottiene la scomposizione mediante la semplice relazione del prodotto scalare :\n\n$$\n\\mathbf{v} = \\alpha \\mathbf{e}_1 + \\beta \\mathbf{e}_2\n$$ {#eq-1}\n\ndove $\\mathbf{e}_1$ ed $\\mathbf{e}_2$ sono i versori delle direzioni mutuamente ortogonali ($\\mathbf{e}_1 \\cdot \\mathbf{e}_2 = 0$).\nGrazie alla proprietà di ortogonalità della base posso scrivere infatti:\n\n$$\n\\alpha = \\mathbf{v}\\cdot\\mathbf{e}_1 =  (\\alpha \\mathbf{e}_1 + \\beta \\mathbf{e}_2)\\cdot \\mathbf{e}_1 \\\\\n\\beta = \\mathbf{v}\\cdot\\mathbf{e}_2\n$$ {#eq-2}\n\nche definisce l'operazione di scomposizione tramite la semplice operazione di prodotto scalare.\nL'@eq-1 suggerisce di rappresentare il vettore in una maniera diversa, ovvero considerando le sole componenti lungo i due versori:\n\n$$\n\\mathbf{v}=[\\alpha, \\beta]\n$$\n\ntale rappresentazione consente di effettuare considerazioni sul vettore solamente tramite le sue componenti nelle direzioni della base ortogonale di vettori $\\mathbf{e}_1$ ed $\\mathbf{e}_2$.\nOvvero il vettore può essere 'pensato' come una 'freccia' nel piano oppure come insieme di componenti.\nTale concetto è illustrato nella figura seguente.\n\n![Corrispondenza tra un vettore nel piano e l'insieme delle sue componenti lungo una coppia di versori ortogonali](images/fig2.1.png){#fig-2_1}\n\nLa relazione di eguaglianza espressa in @eq-1 garantisce la reversibilità, ovvero dati i parametri della trasformazione in componenti vettoriali lungo una coppia di direzioni ortogonali, è possibile risalire esattamente al vettore originario.\nVedremo che non tutte le trasformazioni sono reversibili e che la reversibilità garantisce una corretta interpretazione delle operazioni effettuate nel dominio della trasformata.\nIntroducendo ad esempio il concetto di filtro sulle componenti vettoriali come quell'operatore che fornisce la sola componente lungo $\\mathbf{e}_1$ , si ottiene il valore del coefficiente $\\alpha$ che si sa essere esattamente corrispondente al vettore tolta la componente lungo l'altra direzione.\nQuesta sembrerebbe una tautologia, ma, applicata alle trasformazioni di segnale, giustifica e fornisce la corretta interpretazione alle operazioni di manipolazione in frequenza quali il filtraggio: in una comune operazione di filtraggio passa-basso si ha la certezza di aver eliminato le componenti armoniche del segnale ad alta frequenza e di aver lasciato inalterate le rimanenti.\n\nDalla @eq-1 e la @eq-2 si ottiene:\n\n$$\n\\mathbf{v} = (\\mathbf{v}\\cdot\\mathbf{e}_1) \\mathbf{e}_1 + (\\mathbf{v}\\cdot \\mathbf{e}_2) \\mathbf{e}_2\n$$\n\nche riassume i concetti prima espressi.\n\n## Scomposizione di un segnale tempovariante continuo su di una base di funzioni orto-normali\n\nPer i segnali temporali vale un ragionamento analogo.\nPer semplicità considereremo lo sviluppo in serie invece della trasformata di Fourier in quanto da esso è poi possibile, tramite passaggio al limite, ricavare la formula della trasformata [^1].\n\n[^1]: F. Angrilli, Misure Meccaniche e Termiche, Cedam 2005\n\nUna funzione periodica gode della proprietà che $g(t)=g(t+nT)$ per ogni valore $n$ intero.\n$T$ è il periodo ed $f_0 = 1/T$ è la **frequenza fondamentale**, mentre $\\omega = 2\\pi f$ è la **pulsazione**.\nEssa può essere scomposta in serie di Fourier come segue.\n\nAvendo un segnale $s(t)$, rappresentabile nel dominio del tempo, si può definire lo sviluppo di Fourier tramite la relazione invertibile:\n\n$$\ng(t)=\\frac{1}{2}a_o + \\sum_{n=1}^{\\infty}a_n \\cos(\\omega_n t) + \\sum_{n=1}^{\\infty}b_n \\sin(\\omega_n t)\n$$ {#eq-sft}\n\nDove $\\omega_n = 2\\pi n f_0$.\n\nI coefficienti $a_n$ e $b_n$ vengono ricavati secondo le seguenti relazioni:\n\n$$\na_n = \\frac{2}{T}\\int_0^T g(\\tau)\\cos(\\omega_nt)d\\tau \\\\\nb_n = \\frac{2}{T}\\int_0^T g(\\tau)\\sin(\\omega_nt)d\\tau\n$$ {#eq-ab-coeffs}\n\nLa @eq-sft vuol dire scomporre la funzione $g(t)$ secondo la base di funzioni ortogonali armoniche.\n\n**NOTA**: la @eq-sft corrisponde anche alla media delle componenti del prodotto elemento per elemento tra i due vettori.\n\n### Definizione di prodotto scalare tra funzioni continue e discrete\n\nIl prodotto scalare tra segnali/funzioni periodiche si definisce come:\n\n$$\ng(t)\\bullet f(t)=\\frac{1}{T}\\int_0^T g(\\tau)f^*(\\tau)d\\tau\n$$ {#eq-prodscal}\n\ndove con $f^*(t)$ si intende la funzione **complessa coniugata** di $f(t)$ che, nel caso di funzioni reali, coincide con se stessa.\n\nLe stesse funzioni digitalizzate $g_k$ ed $f_k$ consistono nei due vettori $\\{g(1), g(2),\\dots, g(N)\\}$ e $\\{f(1), f(2),\\dots, f(N)\\}$ e quindi si definisce prodotto scalare tra i segnali digitalizzati:\n\n$$\ng_k\\bullet f_k=\\frac{1}{T}\\sum_{i=1}^N g_i f_i = \\\\\n \\{g(1), g(2),\\dots, g(N)\\} \\bullet \\{f(1), f(2),\\dots, f(N)\\}^T / N\n$$ {#eq-decompose}\n\nDi seguito un esempio in R di scomposizione di un'onda quadra su una base ortogonale e sua ricomposizione sulla stessa base.\nPoi scomposizione e ricomposizione secondo la serie di Fourier.\nSi noti che un'onda quadra che parte con fronte di salita esattamente con il primo campione risulta essere scomponibile solo mediante sinusoidi per cui dimenticheremo le componenti coseno.\n\n### Esempio\n\nDefiniamo le funzioni **prodotto scalare tra segnali digitalizzati** e relativa **norma**.\nLa prima funzione la definiamo come operatore `%ps%`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # secondo le equazioni:\n`%ps%` <- function(A, B) {\n  (t(A) %*% B / length(A)) %>% as.numeric()\n}\n\n# ma anche, più efficientemente:\n`%ps%` <- function(A, B) mean(A*B)\n```\n:::\n\n\n\n\nPer la norma, definiamo la funzione `norm_ps` (dato che `norm` è già definita):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnorm_ps <- function(A) sqrt(A %ps% A)\n\n(1:5) %ps% (5:1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7\n```\n\n\n:::\n\n```{.r .cell-code}\nnorm_ps(1:5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.316625\n```\n\n\n:::\n:::\n\n\n\n\nOra creiamo un segnale onda quadra (il segno dell'onda seno) campionato su 1000 punti tra 0 e 1, con frequenza 2 Hz:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf0 <- 2\nfc <- 1000\nTm <- 1\ndt <- 1/fc\n\nsin_k <- function(x, f, k=1) sin(2*pi*f*k*x)\n\ndf <- tibble(\n  t = seq(dt, Tm, dt),\n  ys = sin_k(t, f0),\n  yq = sign(ys)\n)\n\ndf %>% \n  pivot_longer(-t, names_to = \"signal\") %>% \n  ggplot(aes(x=t, y=value, color=signal)) +\n  geom_line() \n```\n\n::: {.cell-output-display}\n![Onda quadra e corrispondente sinusoide di pari frequenza e ampiezza](teoria_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nCalcoliamo le prime sette componenti della serie, secondo @eq-decompose:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nK <- 7\ncomps <- map_dbl(1:K, \\(k) {\n  s <- sin_k(df$t, f0, k)\n  df$yq %ps% s/norm_ps(s)\n}) %>% zapsmall()\n\ncomps\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9003045 0.0000000 0.3000699 0.0000000 0.1800040 0.0000000 0.1285337\n```\n\n\n:::\n:::\n\n\n\n\nInfine approssimiamo l'onda quadra come somma delle prime 7 componenti:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>% \n  mutate(\n    yqk = reduce(1:K, \\(acc, k) {\n      s <- sin_k(t, f0, k)\n      acc + comps[k] * s / norm_ps(s)\n    }, .init=0)\n  ) %>% \n  pivot_longer(-t, names_to = \"signal\") %>% \n  ggplot(aes(x=t, y=value, color=signal)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![Onda quadra e sua approssimazione come composizione dei primi sette termini della serie di Fourier](teoria_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n::: {.callout-note title=\"Esercizi\"}\n1.  Partire da $K=1$ e incrementare di 1 alla volta. Cosa si nota?\n2.  Con $f_0=1$ aumentare $K$ di alcune centinaia e poi vicino a 500. Cosa succede? Esiste un numero $K$ per cui il segnale ricomposto diviene pressoché perfettamente un'onda quadra?\n3.  Mostrare in un grafico i coefficienti in funzione della frequenza.\n4.  Con $f_0 = 4$; aumentate $K$ fino ad ottenere un'onda quadra perfettamente ricomposta. Quanto vale $K$? C'è qualche nesso con il teorema di Nyquist?\n5.  Aumentate ancora $K$, cosa succede? C'è, di nuovo, qualche nesso con il teorema di Nyquist? Che effetto sta subendo il segnale ricostruito?\n:::\n\n\n## Spettro di un segnale\n\nDall'esempio qui sopra in cui, per semplicità, ci siamo occupati di un caso in cui sono presenti solo componenti seno abbiamo compreso che lo sviluppo in serie di Fourier di un segnale tempovariante è dato dalla sommatoria pesata di componenti armoniche.\nTali armoniche rappresentano una base di funzioni ortogonali ma non ortonormali.\n\nSi ha infatti:\n\n$$\n\\begin{aligned}\n\\sin(\\omega_nt) \\bullet  \\sin(\\omega_nt) &= \\frac{1}{T}\\int_0^T \\sin^2(\\omega_nt)~dt = \\frac{1}{T}\\int_0^T\\frac{1-2\\cos(2\\omega_nt)}{2}=\\frac{1}{2} \\\\\n\\cos(\\omega_nt) \\bullet  \\cos(\\omega_nt) &= \\frac{1}{T}\\int_0^T \\cos^2(\\omega_nt)~dt = \\frac{1}{T}\\int_0^T\\frac{1+2\\cos(2\\omega_nt)}{2}=\\frac{1}{2} \\\\\n\\cos(\\omega_nt) \\bullet  \\sin(\\omega_nt) &= \\frac{1}{T}\\int_0^T \\sin(\\omega_nt)\\cos(\\omega_nt)~dt = \\frac{1}{T}\\int_0^T\\frac{\\sin(2\\omega_nt)}{2}=0 \\\\\n\\cos(\\omega_nt) \\bullet  \\cos(\\omega_kt) &= \\frac{1}{T}\\int_0^T \\frac{\\cos(\\omega_nt+\\omega_kt)\\cos(\\omega_nt-\\omega_kt)}{2}~dt = 0,\\quad n\\neq k \\\\\n\\sin(\\omega_nt) \\bullet \\sin(\\omega_kt) &= \\dots = 0 \\\\\n\\sin(\\omega_nt) \\bullet \\cos(\\omega_kt) &= \\dots = 0\n\\end{aligned}\n$$ {#eq-sincos}\n\n\nPer ottenere una scomposizione corretta occorre introdurre al denominatore dei coefficienti il quadrato del modulo (delle componenti la base di funzioni) quindi 1/2 che, portato a numeratore, spiega il fattore 2 nelle @eq-ab-coeffs.\n\n![Corrispondenza tra una funzione del tempo e l'insieme delle sue componenti secondo una base di funzioni ortonormali](images/fig2.2.png){#fig-2_2}\n\nPassiamo ora a come rappresentare le funzioni in maniera analoga a quanto facciamo con i vettori.\nLa @eq-sft suggerisce infatti la rappresentazione di @fig-2_2, analoga a quella riportata in @fig-2_1.\n\nSecondo quanto rappresentato in @fig-2_2 si potrebbe ragionare indifferentemente (grazie alla relazione di eguaglianza in @eq-sft sulla funzione del tempo oppure su due funzioni (discrete) che rappresentano le componenti della scomposizione secondo Fourier.\n\nEsiste però una rappresentazione più significativa sia per l'analisi segnali che per la soluzione di equazioni differenziali associate a sistemi lineari.\nPer determinare tale rappresentazione è necessario elaborare la @eq-sft impiegando la formula di Eulero, ovvero i fasori:\n\n$$\ne^{i\\omega_nt} = \\cos(\\omega_nt) + i\\sin(\\omega_nt)\n$$\n\nche porta ad esprimere le funzioni armoniche seno e coseno come:\n\n$$\n\\begin{aligned}\n\\cos(\\omega_nt)&=\\frac{e^{i\\omega_nt}+e^{-i\\omega_nt}}{2} \\\\\n\\sin(\\omega_nt)&=\\frac{e^{i\\omega_nt}-e^{-i\\omega_nt}}{2i} \\\\\n\\end{aligned}\n$$ le quali, sostituite nella @eq-sft, comportano:\n\n$$\n\\begin{aligned}\ng(t) &= \\frac{1}{2}a_o + \\sum_{n=1}^\\infty a_n\\frac{e^{i\\omega_nt}+e^{-i\\omega_nt}}{2} + \\sum_{n=1}^\\infty b_n\\frac{e^{i\\omega_nt}-e^{-i\\omega_nt}}{2i} \\\\\ng(t) &= \\frac{1}{2}a_o + \\frac{1}{2}\\sum_{n=1}^\\infty (a_n-ib)e^{i\\omega_nt}    + \\sum_{n=1}^\\infty (a_n+ib)e^{-i\\omega_nt}\n\\end{aligned}\n$$ dalla quale, ponendo: $$\nG_0 = a_0/2 \\\\\nG_n = (a_n-ib)/2 \\\\\nG_{-n} = (a_n + ib_n)/2 = G^*\n$$ {#eq-7prime} si può scrivere: $$\ng(t)=G_0 + \\sum_{n=1}^{\\infty}G_n e^{i\\omega_nt} + \\sum_{n=-1}^{-\\infty}G_n e^{i\\omega_nt}\n$$ cioè: $$\ng(t) = \\sum_{n=-\\infty}^{\\infty}G_n e^{i\\omega_nt}\n$$ {#eq-ft2}\n\nLe componenti, ovvero quanto ognuna di tali funzioni pesa nella ricostruzione della funzione $g(t)$ del tempo, si ricava in maniera analoga: $$\nG_n = g(t) \\bullet e^{i\\omega_nt}=\\frac{1}{T}\\int_0^T g(\\tau)\\left(e^{i\\omega_n\\tau}\\right)^*~d\\tau = \\frac{1}{T}\\int_0^Tg(\\tau)e^{-i\\omega_n\\tau}~d\\tau\n$$ {#eq-spettro}\n\nTale rappresentazione complessa, anche definita **spettro del segnale**, ha il vantaggio di consentire un'immediata valutazione della risposta di un sistema regolato da equazioni differenziali lineari conoscendo le componenti $G_n$ del segnale in ingresso.\nLa dimostrazione di ciò verrà riportata tra breve nel paragrafo \"Funzione di Trasferimento sinusoidale\".\n\nIn questo caso la **base di funzioni è sia ortogonale** come nel caso delle armoniche pure, **ma anche normale**: $$\ne^{i\\omega_nt}\\bullet e^{i\\omega_kt} = \\frac{1}{T}\\int_0^T e^{i\\omega_n\\tau}\\left(e^{i\\omega_k\\tau}\\right)^*~d\\tau=\\delta_{n,k}\n$$ dove $\\delta_{n,k}$ è il delta di Kroneker.\nNel caso in cui $n = k$ basta seguire i seguenti passaggi: $$\n\\begin{aligned}\ne^{i\\omega_nt}\\bullet e^{i\\omega_kt} &= \\frac{1}{T}\\int_0^T e^{i\\omega_n\\tau}\\left(e^{i\\omega_k\\tau}\\right)^*~d\\tau \\\\\n&= \\frac{1}{T}\\int_0^T (\\cos(\\omega_n\\tau) + i\\sin(\\omega_n\\tau))~(\\cos(\\omega_n\\tau)-i\\sin(\\omega_n\\tau))~d\\tau \\\\\n&= \\frac{1}{T}\\int_0^T \\cos^2(\\omega_n\\tau)~d\\tau + \\frac{1}{T}\\int_0^T \\sin^2(\\omega_n\\tau)~d\\tau = \\frac{1}{2} + \\frac{1}{2} \\\\\n&= 1\n\\end{aligned}\n$$\n\nNel caso in cui $n\\neq k$ la dimostrazione è banale se si considera l'ortogonalità delle funzioni armoniche.\n\nÈ opportuno anche notare come **le componenti** $G_{-n}$ e $G_n$ danno vita a segnali armonici reali.\nSi nota infatti che:\n\n$$\nG_n~e^{i\\omega_nt} + G_{-n}~e^{-i\\omega_nt} = G_n~e^{i\\omega_nt} + G_n^*~(e^{i\\omega_nt})^* = G_n~e^{i\\omega_nt} + (G_n~e^{i\\omega_nt})^*\n$$ che, andando a comporre graficamente i due fasori, fornisce la seguente rappresentazione ed il segnale corrispondente $s_n(t) = 2M_n\\cos(\\omega t+\\phi_n)$\n\n::: {#fig-fasori1 layout-ncol=\"2\"}\n![Fasore e suo coniugato a base della scomposizione](images/fasori1.png){width=\"300\"}\n\n![Coefficiente dello sviluppo in serie di Fourier e suo coniugato](images/fasori2.png){width=\"300\"}\n:::\n\n::: {#fig-fasori2 layout-ncol=\"2\"}\n![Composizione grafica dei due fasori (a)](images/fasori3.png){width=\"300\"}\n\n![Composizione grafica dei due fasori (b)](images/fasori4.png){width=\"300\"}\n:::\n\nLa differenza tra l'espressione dell'equazione @eq-sft e quella della @eq-ft2 è che nel primo caso si tratta di coefficienti $a_n$ e $b_n$ reali, nel secondo di coefficienti complessi di cui, come è schematizzato in @fig-2_3, è possibile rappresentare le due funzioni modulo e fase in funzione della frequenza.\nTali moduli e fasi, è facile convincersene tenendo conto dei passaggi che hanno condotto dalla @eq-sft alla @eq-ft e la rappresentazione dei fasori appena riportata, sono proprio i moduli e le fasi delle componenti armoniche che compongono il segnale $s(t)$.\n\n![Corrispondenza tra un segnale periodico e l'insieme delle componenti secondo una base di funzioni complesse ortonormali oppure con due funzioni discrete che rappresentano l'andamento dell'insieme dei coefficienti in modulo e fase.](images/fig2.3.png){#fig-2_3}\n\nRappresentiamo di nuovo i segnali in maniera analoga a quanto facciamo con i vettori.\nLa @eq-spettro suggerisce ora la rappresentazione di @fig-2_3, analoga a quella riportate in figure @fig-2_2 e @fig-2_1.\n\nLa proprietà della reversibilità, valida per l'eguaglianza espressa nella @eq-sft, permette di effettuare operazioni di manipolazione in frequenza, quindi di antitrasformare tornando nel dominio del tempo avendo la certezza di non aver introdotto ulteriori elaborazioni a causa della doppia trasformazione.\nUn classico esempio è l'operazione di filtraggio passa-basso su segnali aventi una componente additiva di rumore in alta frequenza.\nIn tale caso l'operazione di filtraggio passa-basso assicura l'eliminazione delle sole componenti in alta frequenza ipotizzate appartenenti al rumore.\n\n## Trasformata di Fourier\n\n**Funzioni non periodiche possono essere immaginate come funzioni periodiche dal periodo** $T \\rightarrow \\infty$ e quindi la frequenza fondamentale $f_0 \\rightarrow 0$.\nLe scomposizioni di @eq-ft2 e @eq-spettro assumono la forma definita come Trasformata di Fourier:\n\n$$\n\\begin{aligned}\ng(t) &= \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty G(\\omega)~e^{i\\omega t}~d\\omega \\\\\nG(\\omega) &= \\int_{-\\infty}^\\infty g(t)~e^{-i\\omega t}~dt\n\\end{aligned}\n$$ {#eq-ft} notare la convenzione impiegata per indicare la trasformata di una funzione $g(t)$ con la lettera maiuscola, ovvero come $G(\\omega)$.\n\nDi seguito la dimostrazione delle @eq-ft:\n\nSe definiamo:\n\n$$\nA_n := T \\bullet G_n = \\int_0^Tg(t)~e^{-i\\omega_nt}~dt\n$$ questo corrispondere semplicemente a modificare la definizione di prodotto scalare tra funzioni del tempo, che da $$\nf(t)\\bullet g(t) = \\frac{1}{T}\\int_0^Tf(t)~g(t)^*~dt\n$$ diventa: $$\nf(t)\\bullet g(t) = \\int_0^Tf(t)~g(t)^*~dt\n$$\n\nQuesto serve in quanto, dovendo tendere $T\\rightarrow\\infty$, si avrebbe uno $0$ che moltiplica l'integrale.\nQuesto viene quindi eliminato dalla definizione.\n\nOra facciamo tendere $T\\rightarrow\\infty$: si ottiene: $$\nA_{f=\\frac{n}{T}} = A(\\omega_n) = \\int_{-\\infty}^\\infty g(t)~e^{-i\\omega_nt}~dt\n$$ Questa corrisponde alla seconda delle @eq-ft.\nIn particolare, i coefficienti discreti $A_n$ diventano una funzione continua della frequenza (o pulsazione) in quanto il passo tra frequenze successive diviene infinitesimo.\nDunque, **le funzioni che rappresentano le componenti della scomposizione** (analoghe a quelle rappresentate in @fig-2_3) non saranno più funzioni discrete, bensì continue **in quanto l'intervallo di spaziatura sulle ascisse** (nel dominio della pulsazione) **pari a** $2\\pi/T$ tende a zero.\n\nConsideriamo ora la @eq-ft2:\n\n$$\ng(t) = \\sum_{n=-\\infty}^\\infty G_n~e^{i\\omega_nt} = \\sum_{n=-\\infty}^\\infty \\frac{A_n}{T}~e^{i\\omega_nt} = \\frac{1}{T} \\sum_{n=-\\infty}^\\infty A~e^{i\\omega_nt}\n$$ se facciamo tendere $T\\rightarrow\\infty$, $A_n$ diviene una funzione continua della pulsazione $A(\\omega)$ per cui la sommatoria diviene un integrale ottenendo: $$\n\\int_{-\\infty}^\\infty A(\\omega)~e^{i\\omega t}~df = \\int_{-\\infty}^\\infty A(\\omega)~e^{i\\omega t}\\frac{2\\pi}{2\\pi}~df = \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty A(\\omega)~e^{i\\omega t}~d\\omega\n$$ Che corrisponde alla prima delle @eq-ft.\n\n![Corrispondenza tra un segnale non periodico e l'insieme delle sue componenti secondo una base di funzioni complesse ortonormali oppure con due funzioni continue che rappresentano l'andamento dell'insieme dei coefficienti in modulo e fase.](images/fig2.4.png)\n\n## Rappresentazione dello spettro di un segnale campionato mediante DFT\n\nNell’elaborazione dei segnali occorre passare a segnali di tipo discreto poiché i dati acquisiti dal modulo di acquisizione digitale e registrati sono delle sequenze finite di valori quantizzati, ovvero dei vettori come già visto.\nDunque, nell’elaborazione computerizzata dei segnali non si manipola un segnale $s(t)$, ma un vettore $[s(1), s(2), \\dots, s(N)]$ di N valori $s(n)$ campionati alla frequenza di campionamento $f_c = 1/T_c$.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Segnale digitale campionato da un segnale continuo con 20 campioni](teoria_files/figure-pdf/unnamed-chunk-6-1.pdf)\n:::\n:::\n\n\n\n\nLa **Trasformata di Fourier Discreta** (DFT) è formulata così: $$\ns(n)\\rightarrow S(k) = \\sum_{n=1}^N s(n)~e^{-\\frac{2\\pi i}{N}k(n-1)}\\quad k=0, 1, \\dots, N-1\n$$\n\nCome era prevedibile, ciascun elemento S(k) della trasformata del segnale discreto, ovvero del vettore, si può calcolare come prodotto di due vettori: $$\nS(k) = [s(1), s(2), \\dots, s(N)]\\cdot[1, e^{-\\frac{2\\pi i}{N}k}, e^{-\\frac{2\\pi i}{N}k~2},\\dots, e^{-\\frac{2\\pi i}{N}k~N}]^T\n$$ Ovvero tra il vettore corrispondente al segnale discreto ed uno dei vettori corrispondenti alla base (uno dei segnali discreti complessi $e^{-\\frac{2\\pi i}{N}kn}$ base della scomposizione).\nAnch’essi vettori ortonormali, in altre parole facente parte dei versori nello spazio $\\mathbb R^N$.\nSi noti che **per ricavare le componenti tramite prodotto scalare** definito in @eq-prodscal manca la normalizzazione per $N$.\n\nLa DFT la si può scrivere evidenziando la corrispondenza tra i vettori nel dominio del tempo discreto $s(n)$ e della frequenza discreta, ovvero lo spettro $S(k)$: $$\n[s(1), s(2), \\dots, s(N)]\\rightarrow [S(1), S(2), \\dots, S(N)]\n$$\n\nSi noti come lo spettro $[S(1), S(2), \\dots, S(N)]$ **abbia lo stesso numero di campioni** $N$ del segnale $[s(1), s(2), \\dots, s(N)]$.\n\nÈ importante ora capire: cosa rappresentano i diversi coefficienti $S(k)$?\nA che frequenze corrispondono i vari $k$?\n\n**Consideriamo** $S(1)$ che corrisponde a frequenza nulla: $K$ parte da $0$.\nStiamo moltiplicando per un segnale costante che possiamo immaginare come un segnale armonico avente periodo infinito (inverso della frequenza: $1/0 = +\\infty$).\n\nEsso è pari a: $$\nS(1)=S(k=0)=\\sum_{n=1}^N s(n)~e^0 = \\sum_{n=1}^N s(n)\n$$ Quindi è pari alla somma dei campioni del segnale.\nSi noti che si ha quindi $S(1) = N \\bar{s}$, sove $\\bar s$ è la media del segnale sull'intervallo considerato.\n\n**Consideriamo** $S(2)$: $$\nS(2)=S(k=1)=[s(1), s(2), \\dots, s(N)]\\cdot[1, e^{-\\frac{2\\pi i}{N}}, e^{-\\frac{2\\pi i}{N}\\cdot 2},\\dots, e^{-\\frac{2\\pi i}{N}\\cdot N}]^T\n$$\n\nQuindi $S(2)$, divisa per $N$, fornirà la componente del segnale $s(n)$ lungo la prima armonica.\nSi noti infatti che l’esponenziale complesso ha fase che parte da $0$ ed arriva a $2\\pi$ esattamente in $N$ campioni eseguendo quindi un solo periodo o giro per il *fasore* corrispondente.\nIl periodo totale di campionamento è pari a $(N-1)T_c$\n\nDi conseguenza la frequenza corrispondente sarà $\\frac{1}{(N-1)T_c}$.\n\n**Consideriamo** $S(3)$: $$\nS(3)=S(k=3)=[s(1), s(2), \\dots, s(N)]\\cdot[1, e^{-\\frac{4\\pi i}{N}}, e^{-\\frac{4\\pi i}{N}\\cdot 2},\\dots, e^{-\\frac{4\\pi i}{N}\\cdot N}]^T\n$$\n\n$S(3)$, diviso sempre per $N$ è la componente del segnale $s(n)$ lungo la seconda armonica.\nSi noti che l’esponenziale complesso ha fase che parte da $0$ ed arriva a $4\\pi$ esattamente in $N$ campioni eseguendo quindi due periodi, o giri, per il fasore corrispondente.\nDi conseguenza la frequenza corrispondente sarà $\\frac{2}{(N-1)T_c}$.\nE così via.\n\nContinuando in questo modo, l’ultimo valore dello spettro corrisponderebbe alla frequenza $1/T_c$ pari alla frequenza di campionamento $f_c$.\nMa sappiamo che ciò non è possibile.\nIl teorema di Nyquist assegna infatti significato alla sola banda $0\\div f_c/2$.\nè questo il motivo per cui dalla frequenza di Nyquist ($f_c/2$) in poi si ha una ripetizione dello spettro tramite le componenti negative che, assieme alle corrispondenti positive, consentono di ottenere le armoniche come segnali reali.\n\n![Rappresentazione dei coefficienti della scomposizione di Fourier mediante DFT. La trasformazione possiede contenuto informativo sino alla frequenza di Nyquist, oltre si ha uno specchio delle componenti (per segnali reali il modulo sarà simmetrico, la fase antisimmetrica).](images/dft.png){#fig-cap}\n\nSi veda la @sec-example-fft per un esempio.\n\n\n\n## La trasformata di Fourier rapida\n\nCome visto sopra, la trasformata di Fourier scompone una serie temporale nelle sue frequenze costituenti, rappresentandola cioè come una somma di oscillazioni armoniche.\n\n:::: {.content-visible when-format=\"html\"}\n::: column-margin\n![Fonte: nti-audio.com](images/fft.png)\n:::\n::::\n\nL'algoritmo FFT è una procedura computazionale molto efficiente per calcolare la **trasformata di Fourier** discreta di un segnale, o serie temporale, campionato.\nSe $x$ è la serie storica e $X$ è la sua trasformata:\n\n$$\nX(k) = \\sum_{n=1}^N x(n) e^{-j2\\pi k n/N}\n$$\n\ndove $k=1, 2, \\dots, N-1$ e $N$ è il numero di osservazioni campionate.\n\nSi noti che la trasformata di un segnare reale è una serie di numeri complessi, la cui parte reale rappresenta l'**intensità** mentre la parte immaginaria rappresenta la **fase**.\n\n### Esempio\n\n#### Creiamo una serie di dati {#sec-example-fft}\n\nCreiamo una serie temporale ottenuta combinando sinusoidi con diversi parametri di ampiezza $w$, frequenza $f$ e fase $\\phi$.\nPer farlo definiamo una funzione di supporto:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsignal <- function(t, pars, rad=FALSE) {\n  stopifnot(is.data.frame(pars))\n  if (!rad) {\n    pars$phi <- pars$phi/180*pi\n    pars$f <- 2*pi*pars$f\n  }\n  with(\n    pars,\n    map_dbl(t, \\(t) map_vec(seq_along(w), ~ w[.]*sin(t*f[.]+phi[.])) %>% sum())\n  )\n}\n```\n:::\n\n\n\n\nOra creiamo un segnale composto da tre sinusoidi,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npars <- tibble(\n  w = c(1, 0.2, 0.5, 0.25),\n  f = c(4, 10, 2, 30),\n  phi = c(0, 0, 0, 90)\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Tabella dei parametri\n\n| $w$ (-)| $f$ (Hz)| $\\phi$ (°)|\n|-------:|--------:|----------:|\n|    1.00|        4|          0|\n|    0.20|       10|          0|\n|    0.50|        2|          0|\n|    0.25|       30|         90|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- tibble(\n  t = seq(0, 10, length.out = 5000),\n  y = signal(t, pars, rad=FALSE) + rnorm(length(t), 0, 0.5) + 1.25\n) \n\ns %>% \n  ggplot(aes(x=t, y=y)) +\n  geom_line(linewidth=0.1)\n```\n\n::: {.cell-output-display}\n![Segnale composto, con rumore normale](teoria_files/figure-pdf/unnamed-chunk-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n#### Spettrogramma mediante FFT\n\nR mette a disposizione la funzione `fft()` nella libreria base:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.fft <- fft(s$y)\n\nsummary(s.fft)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Length   Class    Mode \n   5000 complex complex \n```\n\n\n:::\n:::\n\n\n\n\nQuindi la trasformata è un vettore complesso con lo stesso numero di osservazioni del segnale iniziale.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    i = 1:n(),\n    fft = fft(y),\n    intensity = Mod(fft),\n    phase = Arg(fft)/pi*180\n  ) %>% \n  ggplot(aes(x=i, y=intensity)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![FFT grezza](teoria_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nCosa c'è in ascissa?\nLa trasformata copre un intervallo di frequenze $[0, N/T]$, con $T=N\\delta t$ la durata complessiva del segnale.\nL'intensità dei picchi (cioè il modulo del valore complesso) corrisponde invece all'ampiezza delle componenti, scalata con il numero di osservazioni:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.fft <- s %>% \n  mutate(\n    i = 1:n()-1,\n    fft = fft(y),\n    intensity = Mod(fft) / n() * 2,\n    phase = Arg(fft)/pi*180,\n    f = i / max(t)\n  ) %>% \n  slice_head(\n    n = nrow(.)/2\n  )\n```\n:::\n\n\n\n\nMessa in grafico otteniamo lo **spettro in frequenza** del segnale:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns.fft %>% \n  ggplot(aes(x=f, y=intensity)) +\n  geom_vline(xintercept=pars$f, color=\"red\", linewidth=0.25) +\n  geom_line(linewidth=0.2) +\n  geom_point(size=0.5) +\n  coord_cartesian(xlim=c(0, 35)) +\n  labs(x=\"frequenza (Hz)\", y=\"intensità (-)\")\n```\n\n::: {.cell-output-display}\n![FFT riscalata. In rosso le frequenze originali nella tabella `pars`](teoria_files/figure-pdf/unnamed-chunk-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n### Finestre\n\nConsideriamo un segnale sinusoidale privo di disturbo, campionato per un tempo pari a 10 volte il suo periodo più mezzo periodo:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npars <- tibble(\n  w = c(1),\n  f = c(10),\n  phi = c(0)\n)\n\ns <- tibble(\n  t = seq(0, 1+1/pars$f/2, length.out = 512),\n  y = signal(t, pars, rad=FALSE) + rnorm(length(t), 0, 0.0)\n) \n\ns %>% \n  ggplot(aes(x=t, y=y)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](teoria_files/figure-pdf/unnamed-chunk-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nOra osserviamo la FFT\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    f = 0:(n()-1)/max(t),\n    fft = fft(y),\n    intensity = Mod(fft) / n() * 2,\n    phase = Arg(fft)/pi*180\n  ) %>% \n  slice_head(n=nrow(.)/2) %>% \n  ggplot(aes(x=f, y=intensity)) +\n  geom_vline(xintercept=10, linetype=2, color=\"red\") +\n  geom_spoke(aes(angle=pi/2, y=0, radius=intensity), linewidth=0.2) +\n  geom_point(shape=21) +\n  coord_cartesian(xlim=c(0, 100))\n```\n\n::: {.cell-output-display}\n![](teoria_files/figure-pdf/unnamed-chunk-16-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nCome si vede, la FFT è allargata, in maniera inattesa, attorno al picco a 10 Hz: **come mai?**\n\nBisogna ricordare che la FFT assume che il segnale sia periodico e campionato per un numero di cicli interi.\nCioè è come se il segnale si ripetesse all'infinito uguale a se stesso dopo (e prima) la fine del campionamento.\nNel nostro caso, quindi, è come se il segnale fosse come il seguente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% mutate(step=\"A\") %>% \n  bind_rows(mutate(s, step=\"B\", t=t+last(t))) %>% \n  ggplot(aes(x=t, y=y, color=step)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](teoria_files/figure-pdf/unnamed-chunk-17-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nÈ evidente come ogni $\\Delta T=1.05+0.05$ secondi ci sia un evento con una discontinuità sulla derivata del segnale, che si ripete periodicamente.\nCioè si ha un evento con un ampio contenuto in frequenza (per ottenere uno spigolo bisogna sommare molte componenti!) attorno alla frequenza pari all'inverso della durata del campionamento.\nÈ altrettanto evidente come, ad eccezione del caso in cui la durata del campionamento è un multiplo esatto di tutti i periodi contenuti nel segnale, ciò significa che la parte a bassa frequenza dello spettro sarà sempre sporcata alla frequenza pari all'inverso della durata del campionamento.\n\n::: {.callout-note title=\"Esercizio\"}\nProvare a modificare i parametri di frequenza e durata del campionamento per osservare il risultato.\n:::\n\nPer mitigare questo problema si ricorre alla **finestratura** (*windowing*) del segnale: si moltiplica il segnale per una funzione che va a zero, o quasi, all'inizio e alla fine del campionamenti.\nEsistono diverse funzioni di finestratura, le più utilizzate sono quella di **Hamming** e quella di **Hann**.\n\nIl pacchetto `gsignal` le mette a disposizione entrambi (ed altre):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    i = 1:n(),\n    win = hann(n()),\n    yw = y * win\n  ) %>% \n  ggplot(aes(x=i)) +\n  geom_line(aes(y=win), color=\"red\", linetype=2) +\n  geom_line(aes(y=-win), color=\"red\", linetype=2) +\n  geom_line(aes(y=yw))\n```\n\n::: {.cell-output-display}\n![](teoria_files/figure-pdf/unnamed-chunk-18-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nA questo punto il segnale è ovviamente perfettamente periodico e, se calcoliamo la FFT del segnale modificato con la finestra di Hann, otteniamo:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    f = 0:(n()-1)/max(t),\n    yw = hann(n()) * y,\n    fft = fft(yw),\n    intensity = Mod(fft) / n()*2,\n    phase = Arg(fft)/pi*180\n  ) %>% \n  slice_head(n=nrow(.)/2) %>% \n  ggplot(aes(x=f, y=intensity)) +\n  geom_vline(xintercept=10, linetype=2, color=\"red\") +\n  geom_spoke(aes(angle=pi/2, y=0, radius=intensity), linewidth=0.2) +\n  geom_point(shape=21) +\n  coord_cartesian(xlim=c(0, 100))\n```\n\n::: {.cell-output-display}\n![](teoria_files/figure-pdf/unnamed-chunk-19-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nPossiamo osservare come il contributo della durata del campionamento sia pressoché svanito, anche se risulta ovviamente ridotta l'intensità dei picchi a 10 Hz, dato che l'ampiezza media del segnale è anch'essa ridotta.\n\n::: {.callout-note title=\"Esercizio\"}\nProvare a cambiare funzione finestra utilizzando `hamming()` o una delle altre finestre messe a disposizione da `gsignal`.\n:::\n\n\n## Tabella riassuntiva\n\n+------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+--------------------------------------------------------+\n| Oggetto                                                                | Sviluppo in serie o scomposizione dell'oggetto                                                  | Calcolo coefficienti                                   |\n+========================================================================+=================================================================================================+========================================================+\n| Vettore $\\mathbf v$                                                    | $\\mathbf{v} = \\alpha \\mathbf{e}_1 + \\beta \\mathbf{e}_2$                                         | $\\alpha = \\mathbf{v}\\cdot\\mathbf{e}_1$                 |\n|                                                                        |                                                                                                 |                                                        |\n|                                                                        | dove $\\mathbf e_1, \\mathbf e_2$ sono i versori di una base ortogonale                           | $\\beta = \\mathbf{v}\\cdot\\mathbf{e}_2$                  |\n+------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+--------------------------------------------------------+\n| Segnale periodico $g(t)$ nel tempo continuo (sviluppo di Fourier)      | $g(t)=\\frac{a_0}{2}+\\sum_{n=1}^\\infty a_n\\cos(\\omega_nt) +\\sum_{n=1}^\\infty b_n\\sin(\\omega_nt)$ | $a_n=\\frac{2}{T}\\int_0^Tg(t)\\cos(\\omega_nt)~dt$        |\n|                                                                        |                                                                                                 |                                                        |\n| Segnale periodico $g(t)$ nel tempo continuo (sviluppo di Fourier)      | dove $\\omega_n=2\\pi nf_0$                                                                       | $b_n=\\frac{2}{T}\\int_0^Tg(t)\\sin(\\omega_nt)~dt$        |\n+------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+--------------------------------------------------------+\n| Segnale periodico $g(t)$ nel tempo continuo (sviluppo mediante fasori) | $g(t)=\\sum_{n=-\\infty}^\\infty G_n~e^{i\\omega_n t}$                                              | $G_n=\\frac{1}{T}\\int_0^T g(t)~e^{-i\\omega_nt}~dt$      |\n|                                                                        |                                                                                                 |                                                        |\n|                                                                        | dove $\\omega_n = 2\\pi n f_0$                                                                    |                                                        |\n+------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+--------------------------------------------------------+\n| Segnale generico, NON periodico nel tempo continuo                     | $g(t)=\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty G(\\omega)~e^{i\\omega t}~dt$                           | $G(\\omega=\\frac{1}{T}\\int_0^T g(t)~e^{-i\\omega_nt}~dt$ |\n+------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+--------------------------------------------------------+\n| Segnale digitale $s(n)=[s(1),s(2),\\dots,s(N)]$                         | $s(n)=\\frac{1}{N}\\sum_{k=0}^{N-1}S(k)~e^{\\frac{2\\pi i}{N}k(n-1)}$                               | $S(K)=\\sum_{n=1}^{N}s(n)~e^{-\\frac{2\\pi i}{N}k(n-1)}$  |\n|                                                                        |                                                                                                 |                                                        |\n|                                                                        | $n=1, 2, \\dots, N$                                                                              | $k=0, 1, \\dots, N-1$                                   |\n+------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+--------------------------------------------------------+\n\n: Riassunto delle relazioni principali. {#tbl-riassunto .striped}\n\nNotare che per **segnali digitali**, campionati in un intervallo di tempo finito e quantizzati, non ha senso chiedersi se siano periodici o meno.\nSemplicemente non lo sappiamo.\nIn ogni caso la minima armonica contenuta vale 1/(intervallo di acquisizione) e ci saranno le sue multiple in modo analogo ai segnali periodici nel tempo continuo.\n\n\n## Alcune proprietà della trasformata di Fourier\n\nLa trasformata di Fourier gode delle proprietà elencate in @tbl-ftprop.\n\n+------------------+-----------------------------------------------------------------+\n| Proprietà        | Relazione nel dominio del tempo e dello spettro                 |\n+==================+=================================================================+\n| Linearità        | $a x(t) + b y(t)\\rightarrow a X(\\omega) + b Y(\\omega)$          |\n+------------------+-----------------------------------------------------------------+\n| Derivata         | $\\dot x(t) \\rightarrow i\\omega X(\\omega)$                       |\n+------------------+-----------------------------------------------------------------+\n| Integrale        | $\\int_0^t x(\\tau)~d\\tau \\rightarrow \\frac{1}{i\\omega}X(\\omega)$ |\n+------------------+-----------------------------------------------------------------+\n| Variazione scala | $x(at)\\rightarrow\\frac{1}{|a|}X\\left(\\frac{\\omega}{a}\\right)$   |\n+------------------+-----------------------------------------------------------------+\n| Anticipo/Ritardo | $x(t-\\tau)\\rightarrow X(\\omega)~e^{-i\\omega\\tau}$               |\n+------------------+-----------------------------------------------------------------+\n| Modulazione      | $x(t)~e^{-i\\omega_0t}\\rightarrow X(\\omega-\\omega_0)$            |\n+------------------+-----------------------------------------------------------------+\n| Convoluzione     | $x(t) \\otimes y(t)\\rightarrow X(\\omega)Y(\\omega)$               |\n+------------------+-----------------------------------------------------------------+\n| Prodotto         | $x(t)y(t)\\rightarrow X(\\omega)\\otimes Y(\\omega)$                |\n+------------------+-----------------------------------------------------------------+\n\n: Proprietà della trasformata di Fourier {#tbl-ftprop .striped .hover}\n\n### Dimostrazione di alcune proprietà\n\nDi seguito le dimostrazioni:\n\n#### Linearità\n\n$$\n\\begin{aligned}\n\\Im(a~x(t) + b~y(t)) &= \\int_{-\\infty}^\\infty \\left[a~x(t) + b~y(t)\\right]~e^{-i\\omega t}~dt \\\\\n&= \\int_{-\\infty}^\\infty a~x(t)~e^{-i\\omega t}~dt + \\int_{-\\infty}^\\infty b ~x(t)~e^{-i\\omega t}~dt \\\\\n&= a\\int_{-\\infty}^\\infty x(t)~e^{-i\\omega t}~dt + b\\int_{-\\infty}^\\infty~x(t)~e^{-i\\omega t}~dt \\\\\n&= a~X(\\omega) + b~Y(\\omega)\n\\end{aligned}\n$$\n\n#### Derivata\n\nDifferenziando la trasformata inversa di $X(\\omega)$ rispetto al tempo (che equivale a derivare il segnale $x(t)$), si ottiene:\n\n$$\n\\begin{aligned}\n\\frac{d}{dt}x(t) &= \\frac{d}{dt}\\left\\{\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty X(\\omega)~e^{i\\omega t}~d\\omega \\right\\} \\\\\n&= \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty X(\\omega)~\\frac{d}{dt}\\left(e^{i\\omega t}\\right)~d\\omega \\\\\n&= \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty \\left[i\\omega X(\\omega)\\right]~e^{i\\omega t}~d\\omega \\\\\n&= \\Im^{-1}\\left\\{i\\omega X(\\omega)\\right\\}\n\\end{aligned}\n$$\n\n#### Convoluzione\n\n$$\n\\begin{aligned}\nx(t) \\otimes y(t) &= \\int_{-\\infty}^\\infty x(\\tau)y(t-\\tau)~d\\tau \\\\\n\\Im\\left\\{x(t) \\otimes y(t)\\right\\} &= \\int_{-\\infty}^\\infty\\left[ \\int_{-\\infty}^\\infty x(\\tau)y(t-\\tau)~d\\tau \\right]~e^{-i\\omega t}~dt \\\\\n&= \\int_{-\\infty}^\\infty x(\\tau)\\left[ \\int_{-\\infty}^\\infty y(t-\\tau)~e^{-i\\omega t}~dt\\right]~d\\tau  \\\\\n&= \\int_{-\\infty}^\\infty x(\\tau)\\left[ \\int_{-\\infty}^\\infty y(\\xi)~e^{-i\\omega \\xi}~e^{-i\\omega \\tau}~d\\xi\\right]~d\\tau  \\\\\n&= \\int_{-\\infty}^\\infty x(\\tau)~e^{-i\\omega\\tau} \\left[ \\int_{-\\infty}^\\infty y(\\xi)~e^{-i\\omega \\xi}~d\\xi\\right]~d\\tau  \\\\\n&= X(\\omega)Y(\\omega)\n\\end{aligned}\n$$\n\nSi noti che si è sostituita la variabile $t$ con $t-\\tau$ nell’integrale 'interno' nella seguente maniera: $$\n\\begin{aligned}\n\\xi &= t - \\tau \\\\\nt &= \\xi + \\tau \\\\\nd\\xi &= dt\n\\end{aligned}\n$$\n\nGli estremi di integrazione, essendo da $-\\infty$ a $+\\infty$ rimangono invariati.\nQuesta proprietà è connessa con la soluzione di equazioni differenziali lineari che nel dominio del tempo corrisponde ad una operazione di convoluzione, nel dominio della frequenza ad una semplice moltiplicazione di funzioni della frequenza.\n\n#### Ritardo/anticipo\n\n$$\n\\begin{aligned}\n\\Im\\left\\{x(t\\pm t_0)\\right\\} &= \\int_{-\\infty}^\\infty x(t\\pm t_0)~e^{-i\\omega t}~dt \\\\\n&= \\int_{-\\infty}^\\infty x(t')~e^{-i\\omega (t'\\mp t_0)}~dt' \\\\\n&= e^{\\pm i\\omega t_0} \\int_{-\\infty}^\\infty x(t')e^{-i\\omega t'}~dt' \\\\\n&= X(\\omega)~e^{\\pm i \\omega t_0}\n\\end{aligned}\n$$\n\nQuesta proprietà evidenzia come un ritardo/anticipo di un segnale nel tempo ha influenza solo sulla fase dello spettro mentre ne lascia invariato il modulo (il fattore esponenziale con argomento immaginario ha modulo unitario e fase pari all’argomento stesso).\nIntuitivamente questo è ovvio in quanto le componenti dello sviluppo in serie saranno identiche come ampiezza mentre saranno ritardate/anticipate di $t_0$.\nConsiderando una singola componente dello sviluppo inserire ad esempio: $$\na_n\\cos(\\omega_n(t\\pm t_0)) = a_n\\cos(\\omega_n t \\pm \\omega_n t_0)\n$$ che evidenzia lo sfasamento proporzionale alla pulsazione moltiplicato per $t_0$.\n\n\n# Funzioni di trasferimento\n\nLa trasformata di Fourier, grazie alle sue proprietà, consente la manipolazione di\nun’equazione differenziale in modo da farla diventare un’equazione algebrica funzione di\nun parametro complesso: la pulsazione. Questo apre la scena ai metodi classici di signal\nprocessing quali il filtraggio, la definizione di modelli dinamici di sistemi complessi e\nstrumenti di misura, la modellazione del rumore bianco e colorato, etc.\n\n## Trasformazione di un'equazione differenziale in un'equazione algebrica nel dominio delle frequenze: **Funzione di Trasferimento**\n\nSupponiamo di avere un sistema regolato da una equazione differenziale del secondo ordine:\n\n$$\n\\frac{d^2y(t)}{dt^2} + a\\frac{dy(t)}{dt} + b~y(t) = c~u(t)\n$$\n\ndove la $u(t)$ è la forzante, ovvero l'ingresso, mentre la $y(t)$ è la risposta, ovvero l'uscita.\n\nTrasformando secondo Fourier la derivata prima e seconda dell'uscita, tenendo presente le proprietà enunciate in @tbl-ftprop, si ottiene:\n\n$$\n\\frac{dy(t)}{dt}\\rightarrow i\\omega Y(\\omega)\n$$ e $$\n\\frac{d^2y(t)}{dt^2}\\rightarrow i\\omega(i\\omega Y(\\omega))\n$$ e quindi la equazione differenziale diventa: $$\n(i\\omega)^2Y(\\omega) + i\\omega a~Y(\\omega) + b~Y(\\omega) = c~U(\\omega)\n$$ che non è altro se non una equazione algebrica che può essere risolta rispetto all'uscita: $$\nY(\\omega) = \\frac{c}{b + i\\omega~a + (i\\omega)^2}~U(\\omega)\n$$\n\nTale relazione indica che la trasformata dell'uscita del sistema è pari alla trasformata dell'ingresso moltiplicata per una funzione anch'essa della frequenza (o pulsazione) che dipende solamente dalla forma dell'equazione differenziale che regola il sistema stesso, ovvero dai parametri $a$, $b$ e $c$.\nTale funzione complessa viene definita **Funzione di Trasferimento**.\n\nPer convenzione la funzione di trasferimento viene indicata come $H(\\omega)$ per cui la precedente relazione si scrive in forma generale: $$\nY(\\omega) = H(\\omega)U(\\omega)\n$$ {#eq-transffunc}\n\nDalla precedente è immediato ricavare la funzione di trasferimento come rapporto delle trasformate: $$\nH(\\omega) = \\frac{Y(\\omega)}{U(\\omega)}\n$$ In generale l'uscita di un sistema lineare si può ottenere in due maniere:\n\n-   in frequenza: moltiplicazione della trasformata dell'ingresso per la funzione di trasferimento\n-   nel tempo: convoluzione tra ingresso ed antitrasformata della funzione di trasferimento (risposta del sistema ad un impulso ideale).\n\nLa funzione di trasferimento, oltre che esplicitamente ricavata dalla relazione differenziale data dalla fisica del fenomeno, può essere ricavata trasformando la risposta del sistema ad un impulso.\n\nPer fare ciò introduciamo il concetto di *delta di Dirac* che modella **un impulso ideale**.\nEssa vale infinito per un tempo infinitesimo.\nSi definisce $\\delta(t-t_0)$ quella funzione che vale infinito per $t = t_0$ ed è nulla altrove.\nSe integrata tale funzione, avendo dominio infinitesimo ma valore infinito, risulta: $$\n\\int_{-\\infty}^\\infty \\delta(t-t_0)~dt = 1\n$$\n\nCalcoliamone dunque la sua trasformata: $$\n\\delta(t)\\rightarrow \\int_{-\\infty}^\\infty \\delta(t)~e^{-i\\omega t}~dt = \\int_{-\\infty}^\\infty \\delta(t)~e^{-i\\omega (t=0)}~dt = \\int_{-\\infty}^\\infty \\delta(t) = 1\\quad \\forall\\omega\n$$\n\nSe quindi si impiega tale funzione come ingresso ad un generico sistema, si ottiene che $U(\\omega) = 1$ per ogni frequenza e quindi $Y(\\omega) = H(\\omega)$.\nQuesto è il principale motivo per il quale chi si occupa di identificazione/caratterizzazione dei sistemi meccanici impiega martelletti strumentati per imporre degli impulsi sulle strutture e registrarne le vibrazioni nei diversi punti di interesse per ricavare la $h(t)$ ovvero, tramite trasformata di Fourier, la $H(\\omega)$ che lega sollecitazioni nel punto di applicazioni dell'impulso alla risposta nel punto di registrazione delle vibrazioni.\nTorneremo su questo argomento nel terzo paragrafo.\n\nNel prossimo paragrafo evidenziamo un ulteriore punto di vista sulla funzione di trasferimento che può essere vista come quella funzione che in modulo indica l'attenuazione di una qualsiasi armonica venga posta in ingresso ed in fase il suo sfasamento.\nDa ciò prende anche il nome di funzione di trasferimento 'sinusoidale'.\n\n## Funzione di trasferimento sinusoidale\n\nConsideriamo un sistema dinamico lineare caratterizzato da una funzione di trasferimento $H(\\omega)$.\nIniettiamo un ingresso puramente armonico di tipo sinusoidale, come schematizzato nel diagramma a blocchi di @fig-2_5.\n\n![Rappresentazione ingresso-uscita di un sistema dinamico regolato da equazione differenziale lineare.](images/fig2.5.drawio.png){#fig-2_5}\n\nImponendo in ingresso $u(t)=\\sin(\\omega_0 t)$ vogliamo determinare l’uscita $y(t)$.\nVedremo che si determina in maniera immediata dalla conoscenza di modulo e fase della funzione di trasferimento in corrispondenza della pulsazione dell’ingresso.\n\nPer determinarlo passiamo attraverso le trasformate, dunque trasformiamo l’ingresso: $$\nu(t)=\\sin(\\omega_0 t) \\otimes U(\\omega) = \\int_{-\\infty}^\\infty \\sin(\\omega_0 t)~e^{-i\\omega t}~ dt = \\\\\n= \\int_{-\\infty}^\\infty \\sin(\\omega_0 t)(\\cos(\\omega t) - i\\sin(\\omega t)) ~dt\n$$\n\nTale trasformata vale chiaramente zero $\\forall\\omega \\neq\\pm\\omega_0$ grazie alla proprietà di ortonormalità delle funzioni armoniche.\nPer $\\omega = \\omega_0$ ed $\\omega = -\\omega_0$ occorre invece calcolarne i valori.\n\n$$\n\\begin{aligned}\nU(\\omega_0) &= \\int_{-\\infty}^\\infty \\sin(\\omega_0 t)(- i\\sin(\\omega_0 t)) ~dt = -i\\int_{-\\infty}^\\infty \\sin^2(\\omega_0 t)~dt \\\\\n&= -i \\int_{-\\infty}^\\infty \\frac{1-\\cos(2\\omega_0 t)}{2}~dt = -\\frac{i}{2} \\cdot\\infty \\\\\nU(-\\omega_0) &= \\int_{-\\infty}^\\infty \\sin(\\omega_0 t)(i\\sin(\\omega_0 t)) ~dt = i\\int_{-\\infty}^\\infty \\sin^2(\\omega_0 t)~dt \\\\\n&= i \\int_{-\\infty}^\\infty \\frac{1-\\cos(2\\omega_0 t)}{2}~dt = \\frac{i}{2} \\cdot\\infty \\\\\n\\end{aligned}\n$$\n\nVolendo rappresentare lo spettro della funzione seno si ha dunque il grafico in @fig-2_6.\n\n![Rappresentazione dello spettro della funzione sinusoidale. In modulo ha due componenti di valore infinito del primo ordine con modulo 1/2 (ovvero due delta di Dirac di valore 1/2). Come fase due valori antisimmetrici di 90° e -90°. Globalmente lo spettro delle componenti a pulsazioni positive risultano essere i valori coniugati delle componenti a pulsazioni negative, come risulta anche dall’equazione @eq-7prime.](images/fig2.6.drawio.png){#fig-2_6}\n\nGlobalmente la trasformata dell’ingresso si può scrivere quindi come somma di due delta di Dirac: $$\nU(\\omega) = \\frac{i}{2}\\delta(\\omega + \\omega_0)- \\frac{i}{2}\\delta(\\omega-\\omega_0)\n$$ dove con delta di Dirac $\\delta(\\omega-\\omega_0)$ si intende la funzione che vale infinito per $\\omega=\\omega_0)$ ed è nulla altrove.\nSe integrata, tale funzione, avendo dominio infinitesimo ma valore infinito, risulta $\\int_{-\\infty}^\\infty\\delta(\\omega-\\omega_0)~d\\omega$.\nSe come argomento dell’integrale si ha una generica funzione $H(\\omega)$, risulta $\\int_{-\\infty}^\\infty H(\\omega)\\delta(\\omega-\\omega_0)~d\\omega = H(\\omega_0)$.\nQuesto semplicemente perché l’infinito rappresentato dalla delta di Dirac moltiplica il valore della funzione in corrispondenza della pulsazione $\\omega_0$ facendo assumere al prodotto un valore infinito di modulo $H(\\omega_0)$ che, integrato su di un dominio infinitesimo produce un risultato finito pari al valore assunto dalla funzione in corrispondenza della pulsazione $\\omega_0)$.\nA questo punto è immediato determinare il valore della trasformata dell’uscita: $$\nY(\\omega) = H(\\omega)U(\\omega) = H(\\omega) \\left( \\frac{i}{2}\\delta(\\omega + \\omega_0) - \\frac{i}{2}\\delta(\\omega - \\omega_0) \\right)\n$$ che porta ad avere una somma di due delta con moduli pari al valore della funzione di trasferimento in corrispondenza dei due infiniti: $$\nY(\\omega) = H(-\\omega_0)\\frac{i}{2}\\delta(\\omega+\\omega_0) - H(\\omega_0)\\frac{i}{2}\\delta(\\omega-\\omega_0)\n$$\n\nLa funzione di trasferimento può essere scomposta in modulo e fase: $$\nH(\\omega) = M(\\omega)~e^{-i\\Phi(\\omega)}\n$$ per cui si ha: $$\nY(\\omega)=M(\\omega_0)\\frac{i}{2}\\delta(\\omega + \\omega_0)~e^{-i\\Phi(\\omega_0)} - M(\\omega_0)\\frac{i}{2}\\delta(\\omega - \\omega_0)~e^{-i\\Phi(\\omega_0)}\n$$ In cui si sono semplicemente sostituiti i valori e considerata la proprietà dello spettro si un segnale reale: modulo simmetrico e fase antisimmetrica, secondo la @eq-7prime.\n\nConsiderando l’equazione di Eulero: $e^{i\\Phi(\\omega_0)}=\\cos(\\Phi(\\omega_0)) + i\\sin(\\Phi(\\omega_0))$ si ottiene, dopo semplice manipolazione: $$\n\\frac{Y(\\omega)}{M(\\omega_0)} = \\cos(\\Phi(\\omega_0)) \\left[ \\frac{i}{2}\\delta(\\omega+\\omega_0) - \\frac{i}{2}\\delta(\\omega-\\omega_0) \\right] + \\\\\n+ \\sin(\\Phi(\\omega_0)) \\left[ \\frac{1}{2}\\delta(\\omega+\\omega_0) + \\frac{1}{2}\\delta(\\omega-\\omega_0) \\right]\n$$\n\nDel primo termine sappiamo immediatamente calcolare l’antitrasformata avendo appena calcolato la trasformata della funzione seno.\nIl secondo termine è anche immediatamente antitrasformabile in quanto vale: $$\n\\cos(\\omega_0 t) = \\frac{1}{2}\\delta(\\omega+\\omega_0) + \\frac{1}{2}\\delta(\\omega-\\omega_0)\n$$\n\nIn definitiva, quindi: $$\ny(y) = M(\\omega_0)\\cos(\\Phi(\\omega_0)) \\sin(\\omega_0 t) +  M(\\omega_0)\\sin(\\Phi(\\omega_0)) \\cos(\\omega_0 t)\n$$ ovvero: $$\ny(t) = M(\\omega_0)\\sin(\\omega_0t + \\Phi(\\omega_0))\n$$ Che esprime il fatto che se si pone in ingresso ad un sistema regolato da equazioni differenziali lineari un ingresso armonico di modulo unitario e pulsazione $\\omega_0$, l’uscita sarà un’armonica di pari pulsazione $\\omega_0$ ma di modulo pari al modulo della funzione di trasferimento $H(\\omega_0)$ calcolata per la pulsazione $\\omega_0$ e sfasata della fase della funzione di trasferimento $\\Phi(\\omega_0))$ calcolata per la stessa pulsazione $\\omega_0$.\n\n![Trasformata del seno](images/fig2.7.drawio.png){#fig-2_7}\n\n\nA tale risultato era possibile giungere semplicemente considerando la @eq-transffunc: $$\n\\begin{aligned}\nY(\\omega) &= H(\\omega)U(\\omega)=M_H(\\omega)~e^{i\\Phi_H(\\omega)} M_U(\\omega)~e^{i\\Phi_U(\\omega)} \\\\\n&= M_H(\\omega) M_U(\\omega)~e^{i(\\Phi_H(\\omega) + \\Phi_U(\\omega))}\n\\end{aligned}\n$$ che esprime appunto il fatto che i moduli si moltiplicano e le fasi si sommano.\n\n\n\n## Impiego della Funzione di trasferimento per l’elaborazione dei segnali: Filtraggio in frequenza\nUn sistema dinamico lineare per il quale esiste una funzione di trasferimento sinusoidale può rappresentare diverse cose:\n\n* **un elemento che elabora segnali**: la funzione di trasferimento non è utile solo per la soluzione di equazioni differenziali che divengo semplici equazioni algebriche, ma anche per effettuare elaborazioni sulle componenti armoniche di un generico segnale e prevedere quali armoniche conterrà l’uscita in base al suo diagramma di Bode. Tali blocchi di elaborazione possono servire per ridurre il rumore in alta frequenza (filtri passa basso), quello in bassa (filtri passa alto), etc;\n* **uno strumento di misura**: la funzione di trasferimento in questo caso descrive come lo strumento modifica le componenti armoniche di un segnale da misurare (misurando) e prevedere quali armoniche conterrà l’uscita dello strumento in base al suo diagramma di Bode. Va da sé che uno strumento ideale dovrebbe far passare tutte le armoniche del misurando inalterate. Ovvero né alterate in ampiezza e neppure sfasate. In questo modo esiste una corrispondenza esatta (a meno di un fattore di conversione proporzionale) tra uscita e misurando in ingresso. Questo a volte è possibile, a volte no. Come vedremo, se uno strumento è particolarmente 'lento', esso distorcerà significativamente le ampiezze e sfaserà altrettanto significativamente le fasi delle componenti armoniche tanto più si va su in frequenza. In questi casi, per stimare correttamente il misurando, occorre invertire la funzione di trasferimento in una procedura analoga a quella vista per l’operazione di misura di una grandezza statica. Questa procedura può essere definita **Compensazione Dinamica** che vedremo in uno dei prossimi paragrafi.\n\n### Esempio di riduzione del rumore in alta frequenza su di un segnale di temperatura\n\nSi consideri il segnale ed il modulo del suo spettro mostrate in @fig-2_5 (una misura di temperatura tramite PT100 su di una piastra termostatata che regola la temperatura tra due valori soglia). Se il segnale viene posto in ingresso ad un sistema che possiede una funzione di trasferimento passa basso, si ottiene un segnale in uscita con le medesime componenti in bassa frequenza mentre quelle in alta sono attenuate.\n\n![Rappresentazione ingresso-uscita di un sistema dinamico regolato da equazione differenziale lineare.](images/fig2.5.drawio.png){#fig-2_5}\n\n![Schema a blocchi di un processo di riduzione delle componenti in alta frequenza. In altre parole filtraggio in alta frequenza mediante un passa-basso. Nella figura sono rappresentati i segnali d’ingresso ed uscita in funzione del tempo ed il modulo (fase omessa) del loro spettro e la funzione di trasferimento che ha elaborato l’ingresso in modulo e fase.](images/fig-pt100.png){#fig-pt100}\n\nÈ possibile notare che il segnale in uscita non mostra più il rumore originario in alta frequenza in quanto la funzione di trasferimento ha attenuato proprio le componenti armoniche ad alta frequenza che non appartenevano ad un andamento di temperatura. La dinamica termica è infatti generalmente 'lenta'. Appartenevano, ad esempio, al rumore elettromagnetico di natura interferente.\n\nLe tipologie di filtri sono dette\n\n* **passa-basso** nel caso in cui vengano mantenute le componenti a bassa frequenza ed eliminate quelle ad lata frequenza; \n* **passa-alto** nel caso contrario; \n* **passa-banda** nel caso in cui vengano lasciate immutate le componenti appartenenti ad una data frequenza ed eliminate le altre; \n* **elimina-banda** nel caso opposto. \n\nL’**ordine del filtro** coincide con l’ordine del sistema lineare corrispondente al filtro e definisce, nel diagramma di Bode, la pendenza di modulo(espresso nel diagramma logaritmico in decibel per decade) ed andamento della fase. Altro parametro importante è la frequenza di taglio $f_c$ definita come quella frequenza alla quale il segnale viene distorto in modo trascurabile, quindi:\n\n* la massima attenuazione (o amplificazione) della potenza delle armoniche è pari al 50%, ovvero l’ampiezza viene attenuata di un fattore uno su radice di due, in termini logaritmici quindi $\\pm 3$ dB;\n* lo sfasamento è pressoché lineare (introducendo eventualmente un ritardo ma non una distorsione). A tale conclusione si arriva considerando la proprietà dell’anticipo-ritardo della trasformata. \n\nAlla frequenza di taglio corrisponde implicitamente una banda passante che sarà da 0 ad $f_c$ nel caso di passa basso, da $f_c$ ad infinito nel caso di passa alto.\n\n### Filtri online\n\nIl filtro online opera direttamente sul segnale temporale elaborandolo mano mano che esso si presenta, campione dopo campione tramite una successione per ricorrenza. \nLa dimostrazione del fatto che un sistema reale si comporta nel dominio discreto come una successione per ricorrenza la si ottiene:\n\n* moltiplicando la trasformata di un segnale d’ingresso per la funzione di trasferimento\n* antitrasformando \n* discretizzando la derivata \n\nProviamo quanto detto con un filtro del primo ordine avente uno zero ed un polo:\n\n![Filtro con un polo e uno zero](images/fig-filtro-online.drawio.png){#fig-filtro-online}\n\nSappiamo che:\n$$\nY(\\omega) = \\frac{1+i\\omega\\tau_N}{1+i\\omega\\tau_D}U(\\omega)\n$$\nda cui:\n$$\nY(\\omega)(1+i\\omega\\tau_D) = U(\\omega)(1+i\\omega\\tau_N)\n$$\nquindi:\n$$\nY(\\omega)+i\\omega\\tau_DY(\\omega)=U(\\omega)+i\\omega\\tau_nU(\\omega)\n$$\n\nAnti-trasformando otteniamo:\n$$\ny(t) + \\dot y(t)\\tau_D=u(t)+\\dot u(t)\\tau_N\n$$\ne applicando la formula di Eulero per la discretizzazione (anche conosciuta come formula alle differenze finite):\n$$\ny_k+\\frac{y_k-y_{k-1}}{T_c}\\tau_D=u_k\\frac{u_k-u_{k-1}}{T_c}\\tau_n\n$$\ne, in definitiva:\n$$\ny_k\\left(1+\\frac{\\tau_D}{T_c}\\right) = y_{k-1}\\frac{\\tau_D}{T_c}+ u_k\\left(1+\\frac{\\tau_N}{T_c}\\right) - u_{k-1}\\frac{\\tau_N}{T_c}\n$$\nche, normalizzando, diventa la seguente ricorrenza:\n$$\ny_k=y_{k-1}\\frac{\\tau_D/T_c}{1+\\tau_D/T_c} + u_k\\frac{\\tau_N/T_c}{1+\\tau_D/T_c}+u_{k-1}\\frac{\\tau_N/T_c}{1+\\tau_D/T_c}\n$$\n\n**Che significato assumono in R i vettori `A` e `B`?**\n\nSe $n_a$ è l'ordine del denominatore ed $n_b$ è l'ordine del numeratore, $A = [A(1), A(2),\\dots, A(n_a+1)]$, $B = [B(1), B(2),\\dots, B(n_b+1)]$:\n$$\n\\begin{aligned}\na(1)y(n) =& b(1)x(n) + b(2)x(n-1) + \\dots + b(n_b+1)x(n-n_b) + \\\\\n&- a(2)y(n-1)-\\dots-a(n_a+1)y(n-n_a)\n\\end{aligned}\n$$\n\nGrazie alla normalizzazione, si impone $a(1)=1$\n\nNel caso sopra citato della funzione di trasferimento con un polo ed uno zero del primo ordine i vettori A e B sono:\n$$\n\\begin{aligned}\nA &= \\left[ 1\\quad -\\frac{\\tau_D/T_c}{1+\\tau_D/T_c}\\right] \\\\\nB &= \\left[ \\frac{1+\\tau_N/T_c}{1+\\tau_D/T_c} \\quad -\\frac{\\tau_N/T_c}{1+\\tau_D/T_c}\\right]\n\\end{aligned}\n$$\n\nNotare che essendo $n_a = n_b = 1$ entrambi i vettori hanno 2 elementi.\n\nIn R il comando `butter(n, fn)` restituisce i coefficienti della funzione di trasferimento di un filtro Butterworth digitale passa basso di ordine $n$ in grado di operare in tempo reale con frequenza di taglio normalizzata alla frequenza di Nyquist $f_n$.\n\nLa frequenza di taglio per filtri digitali, ovvero filtri che elaborano sequenze di segnali campionati e convertiti viene solitamente normalizzata per la frequenza di Nyquist. Il motivo è semplice: un vettore corrispondente ad un segnale digitale non possiede esplicitamente informazioni circa la frequenza di campionamento per cui ha senso normalizzare il suo massimo contenuto in frequenza (ponendo quindi la fn pari ad 1) ed esprimendo i parametri di elaborazione (quali ad esempio il filtraggio) rispetto a tale valore, quindi tra 0 ed 1.\n\nSi noti come, perdendo l’informazione circa la frequenza o tempo di campionamento è possibile ragionare equivalentemente in termini di numeri di campioni. Per la frequenza di Nyquist ad esempio l’armonica corrispondente ha 2 campioni: $f_c = 1 / 1$ campione, quindi $f_n = fc / 2 = 1 / 2$ campioni, ovvero periodo 2 campioni.\n\n#### Esempi\n\nRiutilizziamo la funzione `signal()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsignal <- function(t, pars, rad=FALSE) {\n  stopifnot(is.data.frame(pars))\n  if (!rad) {\n    pars$phi <- pars$phi/180*pi\n    pars$f <- 2*pi*pars$f\n  }\n  with(\n    pars,\n    map_dbl(t, \\(t) map_vec(seq_along(w), ~ w[.]*sin(t*f[.]+phi[.])) %>% sum())\n  )\n}\n```\n:::\n\n\n\n\nDefiniamo una sinusoide base con due disturbi armonici, più un disturbo normale:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 100\npars <- tibble(\n  w = c(1, 0.1, 0.3),\n  f = c(1/25, 1/5, 1/3),\n  phi = c(0, 0, 0)\n)\n```\n:::\n\n\n\n\nCominciamo con realizzare il grafico del segnale e delle sue componenti:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- tibble(\n  t = 0:N,\n  s = signal(t, pars[1,]),\n  y = signal(t, pars), \n  yn = y + rnorm(length(t), 0, pars$w[1] / 10)\n)\n\ns %>% \n  select(t, sine=s, signal=y, `signal+noise`=yn) %>% \n  pivot_longer(-t) %>% \n  ggplot(aes(x=t, y=value)) + \n  geom_line(aes(color=name)) +\n  labs(x=\"time (s)\")\n```\n\n::: {.cell-output-display}\n![Segnale armonico con disturbo](teoria_files/figure-pdf/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nLa trasformata di Fourier mostra i tre picchi attesi:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    f = 0:(n()-1)/max(t),\n    fft = fft(yn),\n    intensity = Mod(fft) / n()*2,\n    phase = Arg(fft)/pi*180\n  ) %>% \n  slice_head(n=as.integer(nrow(.)/2)) %>%\n  ggplot(aes(x=f, y=intensity)) +\n  geom_spoke(aes(y=0, radius=intensity, angle=pi/2)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![FFT del segnale armonico di riferimento](teoria_files/figure-pdf/unnamed-chunk-23-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nIl filtraggio online viene realizzato in due passi: prima si **progetta il filtro**, selezionando il tipo di filtro e i parametri che si adattano al segnale che si vuole filtrare e alla sua trasformata nel dominio delle frequenze, poi si applica il filtro al segnale.\n\nNel nostro caso scegliamo un filtro di tipo *Butterworth* di ordine 3:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nft <- 2/pars$f[1] / (1/2)\n# Doppio della frequenza base\nfn <- pars$f[1]*2\n# Frequenza di Nyquist\nfny <- 1/(s$t[2] - s$t[1]) / 2\n# Frequenza di taglio\nft <- fn/fny\n# Filtro Butterworth di ordine 3 con cut-off al doppio della frequenza base\n# Il parametro w è normalizzato tra 0 e 1, con 1 = fny\nflt <- butter(3, w=ft)\nflt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$b\n[1] 0.01018258 0.03054773 0.03054773 0.01018258\n\n$a\n[1]  1.0000000 -2.0037975  1.4470540 -0.3617959\n\nattr(,\"class\")\n[1] \"Arma\"\n```\n\n\n:::\n:::\n\n\n\nCome si vede, l'oggetto filtro contiene i due vettori coi coefficienti polinomiali di un modello ARMA.\n\nLa funzione `freqz()` consente di valutare le caratteristiche del filtro:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(fq <- freqz(flt))\n```\n\n::: {.cell-output-display}\n![Caratteristiche del filtro Butterworth di ordine 3](teoria_files/figure-pdf/unnamed-chunk-25-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nIl grafico *Stop band* è lo stesso grafico *Pass band* ma con limiti dell'asse y più ampi, in modo da evidenziare come poco oltre 3 Hz c'è un'attenuazione completa.\n\nGrafici simili possono essere ottenuti in `ggplot` come segue, estraendo direttamente le componenti dall'oggetto restituito da `freqz`. Si noti che la componente `fq$h` va scomposta in modulo e fase; il modulo va poi convertito in decibel (dB) e la fase va \"srotolata\" (`unwrap`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  h = fq$h,\n  mod = 20*log10(Mod(h)),\n  phase = Arg(h) %>% unwrap() / pi * 180,\n  frequency = fq$w,\n) %>% {\n  (ggplot(., aes(x=frequency)) + \n     geom_line(aes(y=mod)) + \n     coord_cartesian(ylim=c(-4, 0.5)) +\n     geom_vline(xintercept=ft, color=\"red\", linetype=2) +\n     labs(y=\"Intensity (dB)\", x=\"\")) /\n  (ggplot(., aes(x=frequency)) + \n     geom_line(aes(y=phase)) +\n     geom_vline(xintercept=ft, color=\"red\", linetype=2) +\n     labs(y=\"phase (°)\", x=\"frequency (Hz)\"))\n}\n```\n\n::: {.cell-output-display}\n![Caratteristiche del filtro Butterworth di ordine 3 (con GGplot)](teoria_files/figure-pdf/unnamed-chunk-26-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\nIl filtro può poi essere applicato con `filter()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    sflt = flt %>% filter(yn)\n  ) %>% \n  select(t, `signal+noise`=yn, sine=s, filtered=sflt) %>% \n  pivot_longer(-t) %>% \n  ggplot(aes(x=t, y=value)) + \n  geom_line(aes(color=name)) +\n  labs(x=\"time (s)\")\n```\n\n::: {.cell-output-display}\n![Segnale di riferimento filtrato](teoria_files/figure-pdf/unnamed-chunk-27-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nCome si vede, il filtro ripulisce sia il disturbo casuale che le armoniche con frequenza superiore alla frequenza di taglio 0.16 Hz., seppure **introducendo un ritardo di fase**.\n\nPer eliminare il ritardo, se il filtro è applicato **offline**, si può ricorrere a `filtfilt()` al posto di `filter()`: questa funzione applica il filtraggio in avanti e indietro, compensando quindi il ritardo:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns %>% \n  mutate(\n    sflt = flt %>% filtfilt(yn)\n  ) %>% \n  select(t, `signal+noise`=yn, sine=s, filtered=sflt) %>% \n  pivot_longer(-t) %>% \n  ggplot(aes(x=t, y=value)) + \n  geom_line(aes(color=name)) +\n  labs(x=\"time (s)\")\n```\n\n::: {.cell-output-display}\n![Segale di riferimento filtrato in avanti e indietro, eliminando il ritardo](teoria_files/figure-pdf/unnamed-chunk-28-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n#### Ricorsione\n\nIl vantaggio dei filtri online è che possono essere calcolati direttamente durante l'acquisizione di un segnale, grazie al fatto che il filtro è esprimibile come una formula di ricorsione.\n\nLa funzione `butter()` restituisce infatti un filtro in forma dei coefficienti di un modello $\\mathrm{ARMA}(p, q)$, per cui è possibile calcolare la nuova osservazione filtrata $y_n$ in funzione delle precedenti osservazioni:\n\n$$\na_1 y_n + a_2y_{n-1} + \\dots + a_{n_a}y_{n-p+1} = b_1x_n + b_2 x_{n-1} + \\dots + b_{n_b}x_{n-q+1}\n$$\n\ndove le $y_i$ sono i valori filtrati, le $x_i$ i valori originari, e i due vettori `A` e `B` contengono i termini $a_i$ e $b_i$, con $a_1 = 1$. Quindi:\n\n$$\ny_n = b_1x_n + b_2 x_{n-1} + \\dots + b_{n_b}x_{n-n_b+1} - \\left(a_2y_{n-1} + \\dots + a_{n_a}y_{n-n_a+1}\\right)\n$$ {#eq-IIR}\n\nPer un filtro Butterworth di ordine $m$, si ha che $p=q=m$ e i vettori `A` e `B` hanno entrambi $m+1$ elementi.\n\nÈ facile implementare la @eq-IIR in un qualsiasi linguaggio di programmazione. Ad esempio in R definiamo una funzione che prende in ingresso una tabella, una nuova osservazione e il filtro (con le componenti ARMA $A$ e $B$), e restituisce la stessa tabella con una riga in più (con il nuovo campione e il valore filtrato con la @eq-IIR). L'inizializzazione della formula ricorsiva viene fatta con una tabella vuota (o `NA`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_filter <- function(t = NA, sample, flt) {\n  # Inizializzazione o aggiornamento tabella:\n  if (!is.data.frame(t) || nrow(t) == 0)\n    t <- tibble(i=1, x=sample, y=0)\n  else\n    t <- add_row(t, i = tail(t, 1)$i + 1, x=sample)\n  A <- flt$a\n  B <- flt$b\n  n <- nrow(t)\n  nb <- min(n, length(B))\n  # Termini Moving Average:\n  MA <- rev(B[1:nb]) * tail(t$x, nb)\n  # Termini Auto-Regressive:\n  AR <- rev(A[1:nb]) * tail(t$y, nb)\n  # Nuova osservazione filtrata:\n  t$y[n] <- sum(MA) - sum(AR, na.rm=TRUE)\n  return(t)\n}\n```\n:::\n\n\n\n\nIn questo modo il filtro può essere applicato **un'osservazione alla volta**, e per questo si chiama *filtro online*: può cioè essere aggiornato durante l'acquisizione del segnale, pena ovviamente un ritardo sul segnale filtrato:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble() %>% \n  my_filter(1, flt) %>% \n  my_filter(2, flt) %>% \n  my_filter(3, flt) %>% \n  my_filter(4, flt) %>% \n  my_filter(5, flt) %>% \n  my_filter(5, flt) %>% \n  my_filter(5, flt) %>% \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|  i|  x|         y|\n|--:|--:|---------:|\n|  1|  1| 0.0101826|\n|  2|  2| 0.0713167|\n|  3|  3| 0.2503604|\n|  4|  4| 0.6058080|\n|  5|  5| 1.1625457|\n|  6|  5| 1.8998389|\n|  7|  5| 2.7409252|\n\n\n:::\n:::\n\n\n\n\nUtilizziamolo sul segnale originale è più evidente il ritardo:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiltered_signal <- tibble()\n\nfor (sample in s$yn) {\n  filtered_signal <- my_filter(filtered_signal, sample, flt)\n}\n\nfiltered_signal %>%\n  ggplot(aes(x=i)) +\n  geom_line(aes(y=y), color=\"red\") +\n  geom_line(aes(y=x))\n```\n\n::: {.cell-output-display}\n![Segnale di riferimento filtrato con la funzione `my_filter()`](teoria_files/figure-pdf/unnamed-chunk-31-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nSfruttando la programmazione funzionale di `purrr`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns$yn %>% \n  reduce(\\(tbl, obs) my_filter(tbl, obs, flt), .init=tibble()) %>% \n  ggplot(aes(x=i)) +\n  geom_line(aes(y=y), color=\"red\") +\n  geom_line(aes(y=x))\n```\n\n::: {.cell-output-display}\n![Segnale di riferimento filtrato con la funzione `my_filter()`, usando `purrr`](teoria_files/figure-pdf/unnamed-chunk-32-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n#### Filtri IIR e FIR\n\nTra i filtri online c'è un'importante differenza, che classifica filtri *Infinite Impulse Response (IIR)* e filtri *Finite Impulse Response (FIR)*: considerando un impulso unitario:\n\n$$\ny(x)=\\begin{cases}\n0 & x < 0 \\\\\n1 & x \\geqslant 0\n\\end{cases}\n$$\nle due classi di filtri si comportano come segue:\n\n- **IIR**: sono filtri con memoria infinita: il valore filtrato dell'impulso mantiene memoria di ogni osservazione precedente e quindi non si stabilizza mai a 1 (seppure avvicinandosi sempre più). Corrispondono a **filtri ARMA**, in cui la parte AR ha un numero di coefficienti maggiore di uno;\n- **FIR**: sono filtri con memoria limitata: dopo un numero di osservazioni pari alla memoria del filtro il valore filtrato è uguale a 1. Corrispondono a **filtri MA** (che ha memoria **finita**), un cui manca la parte AR (che ha memoria **infinita**).\n\nOsserviamo la risposta al gradino dello stesso filtro `flt` sopra definito:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(i=1:100, x=1) %>% \n  mutate(xf = filter(flt, x)) %>% \n  pivot_longer(-i, names_to = \"signal\") %>% \n  ggplot(aes(x=i)) + \n  geom_line(aes(y=value, color=signal)) \n```\n\n::: {.cell-output-display}\n![Risposta all'impulso di un filtro **IIR**](teoria_files/figure-pdf/unnamed-chunk-33-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nSe osserviamo un dettaglio della parte finale (`i>80`), possiamo verificare come in realtà il segnale filtrato non si stabilizzi mai a 1:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(i=1:100, x=1) %>% \n  mutate(xf = filter(flt, x)) %>% \n  dplyr::filter(i>80) %>% \n  pivot_longer(-i, names_to = \"signal\") %>% \n  ggplot(aes(x=i)) + \n  geom_line(aes(y=value-1, color=signal)) +\n  scale_y_continuous(\n    n.breaks = 10,\n    labels = scales::label_scientific(digits=6)\n  )\n```\n\n::: {.cell-output-display}\n![Risposta all'impulso di un filtro **IIR** (dettaglio)](teoria_files/figure-pdf/unnamed-chunk-34-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n:::column-margin\n**Attenzione**: sia il pacchetto `gsignal` che `dplyr` (parte di `tidyverse`) forniscono una funzione `filter()`. Siccome `gsignal` è stato caricato **dopo** `tidyverse`, è necessario disambiguare la funzione desiderata premettendo il nome del pacchetto. Per questo motivo scriviamo `dplyr::filter(i>80)` anziché semplicemente `filter(i>80)`.\n:::\n:::\n\n\nOra creiamo invece un filtro FIR di ordine 3, con la stessa frequenza di taglio, osservando come possa essere rappresentato da un modello MA con 4 termini (3+1):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(flt_fir <- fir1(3, w=ft))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.04355854 0.45644146 0.45644146 0.04355854\nattr(,\"class\")\n[1] \"Ma\"\n```\n\n\n:::\n:::\n\n\n\n\nLe caratteristiche del filtro sono le seguenti:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqz(flt_fir)\n```\n\n::: {.cell-output-display}\n![Caratteristiche di un filtro FIR di ordine 3](teoria_files/figure-pdf/unnamed-chunk-36-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nSi noti, in particolare, che la fase è lineare: ciò è un vantaggio perché può essere facilmente utilizzata per **compensare il ritardo**, come si vedrà più sotto.\n\nLa risposta al gradino è la seguente, notando che dopo tre osservazioni il filtro è identico al segnale:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(i=1:100, x=1) %>% \n  mutate(xf = filter(flt_fir, x)) %>% \n  pivot_longer(-i, names_to = \"signal\") %>% \n  ggplot(aes(x=i)) + \n  geom_line(aes(y=value, color=signal)) \n```\n\n::: {.cell-output-display}\n![Risposta all'impulso di un filtro **FIR**](teoria_files/figure-pdf/unnamed-chunk-37-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nVediamo come si comporta un filtro FIR sul segnale armonico di riferimento. Anzitutto notiamo come la caratteristica del filtro FIR sia meno aggressiva del filtro IIR a parità di banda e di ordine. Pertanto utilizziamo un filtro di ordine superiore:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflt_fir <- fir1(6, w=ft)\ns %>% \n  mutate(\n    sflt = flt_fir %>% filter(yn)\n  ) %>% \n  select(t, `signal+noise`=yn, sine=s, filtered=sflt) %>% \n  pivot_longer(-t) %>% \n  ggplot(aes(x=t, y=value)) + \n  geom_line(aes(color=name)) +\n  labs(x=\"time (s)\")\n```\n\n::: {.cell-output-display}\n![Segnale di riferimento filtrato con filtro FIR](teoria_files/figure-pdf/unnamed-chunk-38-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nDato che il ritardo di fase è lineare, è facile compensarlo: la funzione `grpdelay()` valuta il ritardo, e la funzione `lead()` (cioè `lag()` per ritardi negativi) lo compensa:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflt_fir <- fir1(6, w=ft)\ndelay <- grpdelay(flt_fir)$gd %>% mean() %>% round() %>% as.integer()\n\ns %>% \n  mutate(\n    sflt = flt_fir %>% filter(yn),\n    sflt_nd = sflt %>% lead(delay)\n  ) %>% \n  select(t, `signal+noise`=yn, signal=s, `filtered nd`=sflt_nd) %>% \n  pivot_longer(-t) %>% \n  ggplot(aes(x=t, y=value)) + \n  geom_line(aes(color=name)) +\n  labs(x=\"time (s)\")\n```\n\n::: {.cell-output-display}\n![Segnale di riferimento filtrato con filtro FIR, ritardo compensato](teoria_files/figure-pdf/unnamed-chunk-39-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nOvviamente, la compensazione del ritardo rende un filtro FIR **offline**: se così non fosse, ci consentirebbe di conoscere il futuro.\n\n#### Stabilità\n\nCome abbiamo visto un filtro può essere rappresentato come un processo ARMA. In quanto tale, può presentare problemi di stabilità. Un filtro è detto **stabile** se la sua risposta al gradino decade a zero indefinitamente, e viceversa.\n\nPer verificare la stabilità di un filtro lo si converte in formato *zero-pole-gain*, un formato che rappresenta il filtro come radici dei polinomi al numeratore della funzione di trasferimento (*zeroes*) e come radici del polinomio al denominatore (*poles*):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# poles\n1/(polyroot(flt$a)) %>% zapsmall() %>% rev()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5913983+0.0000000i 0.7061996+0.3362227i 0.7061996-0.3362227i\n```\n\n\n:::\n\n```{.r .cell-code}\n# zeroes\n1/(polyroot(flt$b)) %>% zapsmall() %>% rev()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1+0i -1+0i -1+0i\n```\n\n\n:::\n:::\n\n\n\n\nMediante `gsignal` è più semplice convertire il filtro in formato `Zpg`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflt %>% as.Zpg()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$z\n[1] -1.0000016-2.850647e-06i -1.0000016+2.850647e-06i -0.9999967+0.000000e+00i\n\n$p\n[1] 0.5913984+0.0000000i 0.7061996-0.3362227i 0.7061996+0.3362227i\n\n$g\nNULL\n\nattr(,\"class\")\n[1] \"Zpg\"\n```\n\n\n:::\n:::\n\n\n\n\n**Un filtro è stabile quando tutti i poli sono all'interno del cerchio unitario sul piano immaginario**: \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncircle <- function(r=1, x0=0, y0=0, n=100, phi = 0) {\n  tibble(\n    i = 0:n,\n    theta = i * 2*pi / n,\n    x = x0 + r*cos(theta + phi),\n    y = y0 + r*sin(theta + phi)\n  )\n}\n\nflt %>% as.Zpg() %>% {\n  tibble(\n    zr = Re(.$z),\n    zi = Im(.$z),\n    pr = Re(.$p),\n    pi = Im(.$p)\n  )} %>% \n  ggplot() +\n  geom_point(aes(x=zr, y=zi), shape=21) +\n  geom_point(aes(x=pr, y=pi), shape=4) +\n  geom_path(data=circle(), aes(x=x, y=y), color=\"red\") +\n  coord_equal() +\n  labs(x=\"Real\", y=\"Imaginary\", title=\"Zero-Pole diagram\")\n```\n\n::: {.cell-output-display}\n![Grafico *zero-pole* per fil filtro IIR](teoria_files/figure-pdf/unnamed-chunk-42-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n### Filtri offline\n\nSe non è necessario applicare il filtro durante l'acquisizione ma si può farlo *ex-post*, è possibile ricorrere alla trasformata di Fourier. Il processo è il seguente:\n\n1. Si calcola la FFT del segnale (**senza applicare una finestra**)\n2. Si definisce una *funzione maschera* che, moltiplicata per lo spettro, riduca o annulli le bande di frequenza che si desidera attenuare\n3. si calcola la **trasformata inversa** della trasformata moltiplicata per la maschera.\n\nVediamo ad esempio il caso di un segnale ottenuto da un elettrocardiogramma, con frequenza di 256 Hz per una durata di 10 s, disponibile nel data frame `gsignal::signals`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsignals %>% \n  mutate(\n    t = seq(0, 10, length.out=n()),\n  ) %>% \n  ggplot(aes(x=t, y=ecg)) +\n  geom_line() +\n  labs(color=\"segnale\", x=\"tempo (s)\", y=\"tensione (µV)\")\n```\n\n::: {.cell-output-display}\n![Segnale di elettrocardiogramma](teoria_files/figure-pdf/unnamed-chunk-43-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nOsserviamo il modulo della trasformata: decidiamo di filtrare le frequenze sopra 10 Hz.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsignals %>% \n  mutate(\n    i = (1:n())-1,\n    t = seq(0, 10, length.out=n()),\n    f = i / max(t),\n    fft = fft(ecg),\n    intensity = Mod(fft) / n() * 2\n  ) %>% \n  ggplot(aes(x=f)) +\n  geom_line(aes(y=intensity)) +\n  scale_x_continuous(minor_breaks = scales::minor_breaks_n(11)) +\n  labs(x=\"frequenza (Hz)\", y=\"tensione (µV)\")\n```\n\n::: {.cell-output-display}\n![FFT del segnale ECG](teoria_files/figure-pdf/unnamed-chunk-44-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nPer farlo definiamo una funzione filtro mediante una gaussiana `dnorm()` (anche se potremmo usare altre funzioni a piacere, a seconda del risultato desiderato). Si noti che la funzione maschera deve essere **simmetrica attorno alla frequenza di Nyquist** come lo è la trasformata.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwidth <- 8\noff <- 0\nsig <- signals %>% \n  mutate(\n    i = (1:n())-1,\n    t = seq(0, 10, length.out=n()),\n    f = i / max(t),\n    filter = \n      (dnorm(f, mean=off, sd=width) + dnorm(f, mean=max(f)-off, sd=width)) / \n      dnorm(0, mean=0, sd=width),\n    fft = fft(ecg),\n    fft_f = fft * filter,\n    intensity = Mod(fft) / n() * 2,\n    intensity_f = Mod(fft_f) / n() * 2,\n    phase = Arg(fft)/pi*180\n  ) \n\nsf <- 30\nsig %>% \n  ggplot(aes(x=f)) +\n  geom_line(aes(y=intensity)) +\n  geom_line(aes(y=filter*sf), color=\"red\") +\n  scale_x_continuous(minor_breaks = scales::minor_breaks_n(11)) +\n  scale_y_continuous(\n    sec.axis = sec_axis(~ . / sf, name = \"filter\")\n  )+\n  labs(x=\"frequenza (Hz)\", y=\"tensione (µV)\")\n```\n\n::: {.cell-output-display}\n![FFT del segnale ECG e funzione maschera (in rosso)](teoria_files/figure-pdf/unnamed-chunk-45-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nLa funzione maschera è stata riscalata in modo da valere 1 al suo massimo. Inoltre, l'ultimo grafico riporta la maschera sul secondo asse verticale, per leggibilità.\n\nLa trasformata moltiplicata per la maschera risulta:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsig %>% \n  ggplot(aes(x=f)) +\n  geom_line(aes(y=intensity_f)) +\n  geom_line(aes(y=filter*sf), color=\"red\") +\n  scale_x_continuous(minor_breaks = scales::minor_breaks_n(11)) +\n  scale_y_continuous(\n    sec.axis = sec_axis(~ . / sf, name = \"filter\")\n  )+\n  labs(x=\"frequenza (Hz)\", y=\"tensione (µV)\")\n```\n\n::: {.cell-output-display}\n![FFT del segnale ECG con applicata la funzione maschera](teoria_files/figure-pdf/unnamed-chunk-46-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nA questo punto possiamo anti-trasformare la trasformata mascherata, per ottenere il segnale filtrato e **privo di ritardo**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsig %>% \n  mutate(\n    ecg_f = Re(ifft(fft_f))\n  ) %>% \n  select(t, ECG=ecg, `ECG (filt.)`=ecg_f) %>% \n  pivot_longer(-t) %>% \n  ggplot(aes(x=t)) + \n  geom_line(aes(y=value, color=name)) +\n  coord_cartesian(xlim=c(0,2), ylim=c(-200, 200)) +\n  labs(color=\"segnale\", x=\"tempo (s)\", y=\"tensione (µV)\")\n```\n\n::: {.cell-output-display}\n![Segnale ECG filtrato (dettaglio)](teoria_files/figure-pdf/unnamed-chunk-47-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\nSi noti che la anti-trasformata restituisce un segnale complesso, per cui è necessario scartare la parte immaginaria.\n\n**ESERCIZIO**: cambiare i valori di `off` e `width` per osservare come modificando la maschera cambia il segnale filtrato.\n\n\n# Taratura dinamica\n\n## Sonda PT100\n\nConsideriamo il caso di una sonda PT100 immersa repentinamente in un bagno termostatato. La temperatura della sonda raggiunge quella del bagno secondo la legge:\n\n$$\nT(t) = (T_i - T_f)e^{-\\frac{t}{\\tau}} + T_f\n$$ {#eq-pt100}\n\n\n\n\n\n\n\n\n\nSappiamo che $T_i = 33.4$ °C, $T_f = 95$ °C e stimiamo che l'immersione inizi a $t_0 = 50$ s.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(temp, aes(x=t, y=T)) + \n  geom_line() +\n  geom_line(aes(y=Tn), color=\"red\", linewidth=1/3) +\n  labs(x=\"tempo (s)\", y=\"temperatura (°C)\")\n```\n\n::: {.cell-output-display}\n![Acquisizione con un sensore di temperatura PT100. In rosso la nominale](teoria_files/figure-pdf/unnamed-chunk-49-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n### Primo metodo: intercetta\n\nSecondo la @eq-pt100, a $t=\\tau$ si ha che $T(\\tau) = (T_i-T_f)e^{-1} + T_f$, cioè:\n\n\\begin{align}\nT_f - T(\\tau) &= (T_f - T_i)e^{-1} \\\\\n&= (95 - 33.4) \\cdot 0.368 \\\\\n&= 61.6 \\cdot 0.368 \\\\\n&=  22.661\n\\end{align}\n\ncioè $T(\\tau) = 72.339$ °C. In grafico:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTtau <- Tf - (Tf - Ti)*exp(-1)\n\nggplot(temp, aes(x=t, y=T)) + \n  geom_line() +\n  geom_hline(yintercept = Ttau, color=\"blue\") +\n  labs(x=\"tempo (s)\", y=\"temperatura (°C)\")\n```\n\n::: {.cell-output-display}\n![Identificazione della temperatura $T(\\tau)$](teoria_files/figure-pdf/unnamed-chunk-50-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nCioè risulta graficamente che $\\tau$ è la distanza tra l'inizio del transitorio e l'intersezione con la linea blu. Sui dati:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp %>% \n  select(t, T) %>%          # solo le colonne t e T\n  mutate(t = t - 50) %>%    # traslo i tempi all'inizio\n  dplyr::filter(T<Ttau) %>% # solo i valori < Ttau\n  slice_tail(n=1) %>%       # prendo solo l'ultima riga\n  knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|  t|        T|\n|--:|--------:|\n| 34| 71.52101|\n\n\n:::\n:::\n\n\n\n\n\n\n### Secondo metodo: linearizzazione\n\nLa @eq-pt100 può essere linearizzata così:\n\n\\begin{align}\n\\frac{T(t) -T_f}{T_i - T_f} &= e^{-\\frac{t}{\\tau}} \\\\\n\\ln\\left(\\frac{T(t) -T_f}{T_i - T_f}\\right) &= \\ln(e^{-\\frac{t}{\\tau}}) \\\\\n\\ln\\left(\\frac{T(t) -T_f}{T_i - T_f}\\right) &= -\\frac{t}{\\tau}\n\\end{align}\n\nPosso riorganizzare i dati come segue:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp.l <- temp %>% \n  select(t, T) %>% \n  mutate(t = t - 50) %>%\n  dplyr::filter(t>0 & t < 100) %>% \n  mutate(y = log((T-Tf)/(Ti - Tf))) %>% \n  dplyr::filter(!is.nan(y))\n\ntemp.lm <- temp.l %>% lm(y~t-1, data=.) \ntemp.lm %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ t - 1, data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.32214 -0.01471  0.00533  0.03149  0.22800 \n\nCoefficients:\n    Estimate Std. Error t value Pr(>|t|)    \nt -2.993e-02  8.169e-05  -366.3   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06645 on 198 degrees of freedom\nMultiple R-squared:  0.9985,\tAdjusted R-squared:  0.9985 \nF-statistic: 1.342e+05 on 1 and 198 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\ntau <- round(-1/temp.lm$coefficients, 1)\ncat(paste(\"tau:\", tau))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntau: 33.4\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp.l %>% \n  ggplot(aes(x=t, y=y)) +\n  geom_smooth(method=\"lm\", formula = y~x-1) +\n  geom_point(size=0.5) +\n  labs(x=\"tempo (s)\", \n       y=latex2exp::TeX(\"$\\\\log_{10}(\\\\frac{T-T_f}{T_i-T_f})$ (T in °C)\"))\n```\n\n::: {.cell-output-display}\n![Regressione del modello dopo linearizzazione](teoria_files/figure-pdf/unnamed-chunk-53-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n### Terzo metodo: regressione non-lineare\n\nCon il terzo metodo si usa la regressione non-lineare ai minimi quadrati per ottenere direttamente tutti e tre i parametri $T_i, T_f, \\tau$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp.l <- temp %>% \n  select(t, T) %>% \n  mutate(t = t - 50) %>%\n  dplyr::filter(t>0) \n\nfit <- nls(T~(Ti - Tf)*exp(-t/tau) + Tf, \n    data = temp.l, \n    start = list(\n      Ti=30,\n      Tf=100,\n      tau=10\n    ))\n\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNonlinear regression model\n  model: T ~ (Ti - Tf) * exp(-t/tau) + Tf\n   data: temp.l\n   Ti    Tf   tau \n33.53 95.01 33.69 \n residual sum-of-squares: 143.2\n\nNumber of iterations to convergence: 5 \nAchieved convergence tolerance: 2.752e-06\n```\n\n\n:::\n\n```{.r .cell-code}\ntemp.l %>% \n  modelr::add_predictions(fit, var=\"fit\") %>% \n  ggplot(aes(x=t, y=T)) + \n  geom_line() +\n  geom_line(aes(y=fit), color=\"red\", linewidth=1/4) +\n  labs(x=\"tempo (s)\", y=\"temperatura (°C)\")\n```\n\n::: {.cell-output-display}\n![](teoria_files/figure-pdf/unnamed-chunk-54-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nSi notino i valori iniziali approssimativi passati per i tre parametri. \n\nI vantaggi di questo terzo metodo sono:\n\n* non è necessario stimare **soggettivamente** $T_i$ e $T_f$, ma vengono identificati direttamente dalla regressione\n* definendo il modello per parti (cioè costante per $t<t_i$), è possibile identificare anche $t_i$ (lo si lascia per esercizio)\n* mediante il metodo bootstrap è possibile ottenere gli intervalli di confidenza su tutti e tre i parametri (lo si lascia per esercizio)\n\nPer contro, è computazionalmente più complesso, mentre il primo e al limite anche il secondo metodo possono essere applicati anche \"a mano\".\n\n\n:::{.callout-note title=\"Esercizio\"}\nDefinire una funzione piecewise costante fino a $T_i$ e poi esponenziale e regredire tale funzione, identificando anche $T_i$\n:::\n\n## Considerazioni sulla relazione tra costante di tempo e funzione di trasferimento\n\n:::{.callout-important}\nMancano pagine 53-54.\n:::\n\n# Compensazione o misura dinamica\n\n:::{.callout-important}\nMancano pagine 55-58.\n:::\n\n\n# Determinazione Funzioni di Trasferimento mediante Parametri Concentrati ed Impedenze Generalizzate\n\n:::{.callout-important}\nMancano pagine 66-81, ma i due esempi originariamente in tabella sono qui riportati per esteso nel capitolo seguente.\n:::\n\n\nDi seguito, anziché utilizzare la funzione `gsignal::bodeplot()`, che usa la vecchia interfaccia per i grafici, utilizzeremo una funzione da noi definita, `ggbodeplot()`, basata su `ggplot2`. La definizione di questa funzione non è essenziale.\n\n<details>\n<summary>ggbodeplot function</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(control)\nlibrary(signal)\n\nggbodeplot <- function(tf, fmin=1, fmax=1e4, df=0.01) {\n  # vector of points for each order of magnitude (OOM):\n  pts <- 10^seq(0, 1, df) %>% tail(-1)\n  # vector of OOMs:\n  ooms <- 10^(floor(log10(fmin)):ceiling(log10(fmax)-1))\n  # combine pts and ooms:\n  freqs <- as.vector(pts %o% ooms)\n  # warning: bode wants pulsation!\n  bode(tf, freqs*2*pi) %>% {\n    tibble(f=.$w/(2*pi), `magnitude (dB)`=.$mag, `phase (deg)`=.$phase)} %>%\n    pivot_longer(-f) %>% \n    ggplot(aes(x=f, y=value)) +\n    geom_line() +\n    scale_x_log10(\n      minor_breaks=scales::minor_breaks_n(10), \n      labels= ~ latex2exp::TeX(paste0(\"$10^{\", log10(.), \"}$\"))) +\n    facet_wrap(~name, nrow=2, scales=\"free\") +\n    labs(x=\"frequency (Hz)\")\n}\n```\n:::\n\n\n\n</details>\n\n\n## Esempio: sistema per isolamento da vibrazioni. \n\nCon il metodo delle impedenze generalizzate si ottiene:\n\n$$\nH(i\\omega)=\\frac{V_\\mathrm{out}(i\\omega)}{V_\\mathrm{in}(i\\omega)}=\\frac{C i\\omega + K}{M (i\\omega)^2 + C i\\omega + K}\n$$ {#eq-tf}\n\nLa frequenza naturale del sistema è $f_0=\\frac{1}{2\\pi}\\sqrt{\\frac{K}{M}}$, e l'attenuazione comincia a $\\sqrt{2}f_0$.\n\nPossiamo definire la funzione di trasferimento in @eq-tf con la funzione `control::tf()`, che prende come due argomenti due vettori con i coefficienti della @eq-tf, in ordine decrescente di grado della variabile $i\\omega$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM <- 10\nK <- 1000\nC <- 50\n\n# Frequenza naturale:\nf0 <- 1/(2*pi) * sqrt(K/M)\n\ntf(c(C, K),c(M, C, K)) %>% \n  ggbodeplot(fmin=0.1, fmax=100) +\n  geom_vline(xintercept=c(1, sqrt(2)) * f0, color=\"red\", linetype=2) +\n  labs(title=paste(\n    \"Natural frequency:\", round(f0, 2), \"Hz\", \n    \" - Isolation: >\", round(sqrt(2)*f0, 2), \"Hz\"))\n```\n\n::: {.cell-output-display}\n![Bode plot per il sistema di isolamento da vibrazioni](teoria_files/figure-pdf/unnamed-chunk-56-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n:::column-margin\n**Decibel** --- La magnitudine della funzione di trasferimento è espressa in decibel (dB). Un decibel corrisponde a $10 \\log_{10}(X)$. Tuttavia è d'uso scalare la magnitudine in modo che rappresenti il **rapporto tra le potenze**, che dipende dal quadrato della variabile in oggetto. Quindi l'effettiva relazione diventa $20 \\log_{10}(X)$. \n\nIn altre parole, un rapporto pari a 1:10 sulla variabile corrisponde a 1:100 sulla potenza; quindi se esprimo la magnitudine come $20 \\log_{10}(X)$ significa che un'attenuazione di -10 dB$_{20}$ sul segnale corrisponde a -10 dB$_{10}$ sulla potenza. Ancora più chiaramente: -20 dB sulla magnitudine significa un'attenuazione di 10 volte sul segnale, 100 volte sulla potenza.\n\n\n\n---\n:::\n:::\n\nSi noti che lo stesso risultato si ottiene a partire dalle equazioni della dinamica del sistema, effettuando la trasformata di Laplace $\\mathcal{L}$:\n\n\\begin{align}\nM\\ddot y + C\\dot y + Ky &= C\\dot x + K x \\\\\n&\\downarrow \\mathcal{L}\\left(\\frac{\\mathrm{d}^nx}{\\mathrm{d}t^n}\\right) = s^n X(s) \\\\\nM s^2 Y(s) + C s Y(s) + K Y(s) &= CsX(s) + KX(s)\n\\end{align} \n\ndalla quale otteniamo l'espressione per la funzione di trasferimento:\n\n$$\nH(s) = \\frac{Y(s)}{X(s)} = \\frac{Cs + K}{Ms^2 + Cs  + K }\n$$\nche corrisponde alla @eq-tf a meno della sostituzione $s=i\\omega$.\n\n\n## Esempio: accoppiamento rotativo motore-carico. \n\nCon il metodo delle impedenze generalizzate si ottiene:\n\n$$\nH(i\\omega) = \\frac{1}{I_c (i\\omega)^2 + Ci\\omega + K} = \\frac{1}{I_c/K (i\\omega)^2 + C/K i\\omega + 1}\n$$\n\nLa frequenza naturale può essere ottenuta con la funzione `control::damp()`, campo `omega`:\n\n::: {.cell}\n\n```{.r .cell-code}\nIc <-  10e-3\nK <-  5000\nC <-  1\n\nH <- tf(1,c(Ic/K, C/K, 1)) \nH.d <- damp(H, doPrint=FALSE)\n\nH %>% \n  ggbodeplot(fmin=10, fmax=1e4) +\n  geom_vline(xintercept=c(1, sqrt(2)) * H.d$omega[1]/(2*pi), color=\"red\", linetype=2) +\n  labs(title=paste(\n    \"Natural frequency:\", round(f0, 2), \"Hz\", \n    \" - Isolation: >\", round(sqrt(2)*f0, 2), \"Hz\"))\n```\n\n::: {.cell-output-display}\n![Bode plot per l'accoppiamento rotativo](teoria_files/figure-pdf/unnamed-chunk-57-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n",
    "supporting": [
      "teoria_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}